{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UDWTNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hilasha2/UDWTNet/blob/main/UDWTNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQIX0BjOmGay"
      },
      "source": [
        "# Initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQZ3ixiw0upA"
      },
      "source": [
        "Install PyTorch 1.6.0\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rArgYIH70wL1"
      },
      "source": [
        "!pip install torch===1.6.0+cu101 torchvision===0.7.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unNrJCR1sGV-"
      },
      "source": [
        "Install imgaug\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYEdv5i0sH-Q"
      },
      "source": [
        "# imaug - Library for augmentation\n",
        "# https://imgaug.readthedocs.io/en/latest/source/installation.html\n",
        "!pip uninstall imgaug             # remove old version of imagaug before installing the new version\n",
        "!pip uninstall albumentations    # remove old version of albumentations before installing the new version\n",
        "!pip install git+https://github.com/aleju/imgaug.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8L-aJpkN5LVA"
      },
      "source": [
        "Import libraries\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7Z27lb_5P4w"
      },
      "source": [
        "# Import the necessary libraries\n",
        "import torch                                      # main module that holds all the things you need for Tensor computation\n",
        "import torch.nn as nn                             # fundamental building blocks of neural networks: models, all kinds of layers, activation functions, parameter classes, etc.\n",
        "import torch.nn.functional as F                   # for binary_cross_entropy loss\n",
        "import torch.optim as optim                       # optimizers like SGD, ADAM, etc\n",
        "\n",
        "from torch.utils.data.dataset import Dataset      # for custom data-sets\n",
        "import os                                         # for handling paths\n",
        "from PIL import Image                             # for loading tif images\n",
        "import natsort                                    # for sorting database by order\n",
        "\n",
        "from imgaug import augmenters as iaa              # for image augmentation\n",
        "import imgaug as ia                               # for image augmentation\n",
        "import numpy as np                                # imgaug uses np images\n",
        "from imgaug.augmentables.segmaps import SegmentationMapsOnImage  # classes dealing with segmentation maps.\n",
        "import cv2                                        # image processing methods     \n",
        "import skimage.morphology                         # image processing methods\n",
        "from scipy import ndimage                         # image processing methods\n",
        "\n",
        "import torchvision                                # consists popular datasets. \n",
        "import torchvision.transforms as transforms       # common image transformations\n",
        "import random                                     # random methods\n",
        "import math                                       # mathematical methods library\n",
        "\n",
        "import pdb                                        # breakpoint for debugging: pdb.set_trace(),  n (next), s(step)\n",
        "import matplotlib.pyplot as plt                   # for ploting images, figues\n",
        "import matplotlib.lines \n",
        "from tabulate import tabulate                     # to print as table\n",
        "import time                                       # to time the training\n",
        "from google.colab import drive                    # to mount google drive to save the models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIgel9Pbdjft"
      },
      "source": [
        "Mount Google Drive- to save/load Model, load database\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7N59apsddlOb"
      },
      "source": [
        "# https://medium.com/@ml_kid/how-to-save-our-model-to-google-drive-and-reuse-it-2c1028058cb2\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFRvyVnHiZMF"
      },
      "source": [
        "Set GPU  device\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVIp_-Giibr7"
      },
      "source": [
        "print ('Available GPU devices ', torch.cuda.device_count())\n",
        "# If we have a GPU available, we'll set our device to GPU. \n",
        "# We'll use this device variable later in our code.\n",
        "\n",
        "is_cuda = torch.cuda.is_available()\n",
        "\n",
        "if is_cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"GPU is set\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "CUDA_LAUNCH_BLOCKING = 1 # For debugging CUDA runtime error."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WanXqbHbmU5m"
      },
      "source": [
        "# Data Handling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5n8dy-Kiiij7"
      },
      "source": [
        "Set path to Data base / save Path\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydfD2c7milU7"
      },
      "source": [
        "BaseDataPath=F\"/content/gdrive/My Drive/DeepLearningCourse/Project/Dataset/Training/DIC-C2DH-HeLa\"\n",
        "BaseSavePath=F\"/content/gdrive/My Drive/DeepLearningCourse/Project\"\n",
        "#BaseDataPath=F\"/content/gdrive/My Drive/Dataset/Training/DIC-C2DH-HeLa\"\n",
        "#BaseSavePath=F\"/content/gdrive/My Drive\"\n",
        "\n",
        "Unet_save_name    = 'UNet.pt'\n",
        "DWTNet_save_name  = 'DWTNet.pt'\n",
        "UDWTNet_save_name = 'UDWTNet.pt' # 'UDWTNet_16.pt' 'UDWTNet_3.pt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mxFgBSymOc0"
      },
      "source": [
        " Load database / class CustomDataset\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAuwfnr3mXsE"
      },
      "source": [
        "# https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
        "# https://discuss.pytorch.org/t/how-make-customised-dataset-for-semantic-segmentation/30881\n",
        "\n",
        "\"\"\"\n",
        " CustomDataset loads images and their segmentation from root_dir.\n",
        " returns:\n",
        " imageAsFloatTensor     - Tensor of the cells images. \n",
        " segAsLongTensor        - Binary silver truth segmentation tensor.\n",
        "                        0 = background \n",
        "                        1 = foreground (cells)\n",
        " ThreeSegAsLongTensor - 3 labels silver truth segmentation tensor.\n",
        "                        0 = background\n",
        "                        1 = foreground (cells)\n",
        "                        2 = cell boundaries\n",
        "\n",
        "segDepthAsLongTensor - 16 labels of eneregy levels in depth images.\n",
        "                       Serves as silver truth for DWTNet.                \n",
        "\"\"\"\n",
        "class CustomDataset(Dataset):\n",
        "\n",
        "    def __init__(self, root_dir,generateSeg_depth = False, transform = None):  \n",
        "  \n",
        "        self.root_dir          =  root_dir\n",
        "        self.seg_dir           = os.path.join(self.root_dir +\"_ST\" ,\"SEG\")     # silver truth\n",
        "        self.seg_depth_dir     = os.path.join(self.root_dir +\"_ST\" ,\"DWTNET\")  # silver truth for dwtnet\n",
        "        self.transform         = transform\n",
        "        self.generateSeg_depth  = generateSeg_depth\n",
        "        \n",
        "        self.image_paths     = CustomDataset.sort_files(self.root_dir)\n",
        "        self.seg_paths       = CustomDataset.sort_files(self.seg_dir)\n",
        "        \n",
        "        if self.generateSeg_depth:\n",
        "          CustomDataset.generate_segDepthmap(self.seg_paths, self.seg_depth_dir)\n",
        "        self.seg_depth_paths = CustomDataset.sort_files(self.seg_depth_dir)     \n",
        "\n",
        "    def __getitem__(self, index):\n",
        "      \n",
        "      # Open  images, segmentations and markers\n",
        "      image     = Image.open(self.image_paths[index],'r') # opens as [0-255]\n",
        "      seg_depth = Image.open(self.seg_depth_paths[index], 'r') \n",
        "\n",
        "      # Convert to np array \n",
        "      imageAsNPArray    = CustomDataset.pil_image_to_np_array(image)\n",
        "      segDepthAsNPArray = CustomDataset.pil_image_to_np_array(seg_depth)\n",
        "        \n",
        "      # Images & segmentations augmentation\n",
        "      if self.transform:\n",
        "        imageAsNPArray, segDepthAsNPArray  = \\\n",
        "        self.transform(imageAsNPArray,segDepthAsNPArray) # imgaug supports unit8 images \n",
        "\n",
        "      ## convert segmentation to labels mask\n",
        "      # --- 2 labels images:\n",
        "      BinarySegAsNPArray = np.copy(segDepthAsNPArray)\n",
        "      BinarySegAsNPArray[BinarySegAsNPArray <= 2] = 0\n",
        "      BinarySegAsNPArray[BinarySegAsNPArray > 2] = 1\n",
        "\n",
        "      # --- Conversion to long and float tensors \n",
        "      BinarySegAsLongTensor = torch.LongTensor(BinarySegAsNPArray.astype(np.uint8)) \n",
        "      segDepthAsLongTensor  = torch.LongTensor(segDepthAsNPArray.astype(np.uint8))\n",
        "\n",
        "      imageAsFloatTensor = torch.FloatTensor(imageAsNPArray.astype(np.float))\n",
        "      imageAsFloatTensor = imageAsFloatTensor / 255 \n",
        "      imageAsFloatTensor = imageAsFloatTensor.unsqueeze(0) # add dim\n",
        "\n",
        "      # --- Z-normalization of the image\n",
        "      imageAsFloatTensor = (imageAsFloatTensor  - imageAsFloatTensor.mean()) / imageAsFloatTensor.std()\n",
        " \n",
        "      return imageAsFloatTensor , BinarySegAsLongTensor, segDepthAsLongTensor\n",
        "      \n",
        "    def __len__(self):\n",
        "      return len(self.image_paths)\n",
        "\n",
        "    # Sort files by filename\n",
        "    def sort_files(dir):\n",
        "      paths = []\n",
        "      filelist =  os.listdir(dir)\n",
        "      filelist = natsort.natsorted(filelist,reverse = False) \n",
        "      for file in filelist:\n",
        "        if file.endswith(\".tif\"):\n",
        "          fullpath = os.path.join(dir, file)\n",
        "          paths.append(fullpath)\n",
        "      return paths\n",
        "\n",
        "    # Convert PIL.Image into a uint8 np array\n",
        "    def pil_image_to_np_array(pil_image):\n",
        "      np_image = np.array(pil_image.getdata())\n",
        "      np_image = np_image.astype('uint8')\n",
        "      return np.resize(np_image, [pil_image.width, pil_image.height])\n",
        "      \n",
        "    # generate GT for DWTNet out of the original segmentation image\n",
        "    def generate_segDepthmap(seg_paths, seg_depth_dir):\n",
        "      depth_bins = np.array([0,1,2,3,4,5,7,9,12,15,19,24,30,37,45,54,1000]);\n",
        "\n",
        "      for segfile in seg_paths:\n",
        "        #print(\"opening \" + segfile)\n",
        "        seg = Image.open(segfile , 'r') #opens as uint8\n",
        "        segAsNPArray = CustomDataset.pil_image_to_np_array(seg)\n",
        "        \n",
        "        segDepthAsNPArray= np.zeros (segAsNPArray.shape,dtype= float)\n",
        "        \n",
        "        ids = np.unique(segAsNPArray)   \n",
        "        for i in range(1, len(ids)):\n",
        "          seg_i = np.copy(segAsNPArray)\n",
        "          # convert to mask containing all labels except the current label\n",
        "          cond = seg_i != ids[i]\n",
        "          seg_i [ seg_i != ids[i] ] = 0\n",
        "          seg_i [     seg_i > 0   ] = 1\n",
        "          \n",
        "          #if (seg_i.sum() < 100):\n",
        "          #  continue\n",
        "          \n",
        "          #distance transform\n",
        "          depth_i = ndimage.morphology.distance_transform_edt(seg_i)\n",
        "          segDepthAsNPArray = segDepthAsNPArray + depth_i\n",
        "        \n",
        "        for  i in range(len(depth_bins)-1):\n",
        "          cond_1 = segDepthAsNPArray > depth_bins[i]\n",
        "          cond_2 = segDepthAsNPArray <= depth_bins[i+1]\n",
        "          segDepthAsNPArray [cond_1 & cond_2] = i-1 if i>0 else 0\n",
        "\n",
        "        # save image\n",
        "        if not os.path.exists(seg_depth_dir):\n",
        "          os.makedirs(seg_depth_dir)\n",
        "\n",
        "        save_pth = os.path.join(seg_depth_dir,os.path.basename(segfile))\n",
        "        #print(\"save_pth = \" + save_pth)\n",
        "        im = Image.fromarray(segDepthAsNPArray) # convert to PIL image\n",
        "        im.save(save_pth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4tI3ZXuDZWe"
      },
      "source": [
        "Define show_dataset\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCWaXRx0s7NX"
      },
      "source": [
        "\"\"\"\n",
        "Show only num_images, every jump image. \n",
        "For example, if num_images = 5, jump = 10,\n",
        "then we show only 5 images, every 10th image in the dataset.\n",
        "\"\"\"\n",
        "\n",
        "def show_dataset(dataset, num_images = 5, jump = 10):\n",
        "\n",
        "  # Dataset must at least contain num_images * jump images.\n",
        "  if len(dataset) < jump * num_images :\n",
        "    print(str(len(dataset)) + \n",
        "           ' = len(dataset) < (jump * num_images) = ' \n",
        "           + str(jump * num_images))\n",
        "    return;\n",
        "  \n",
        "  fig = plt.figure(figsize = (15,10))\n",
        "  img_idx = 0\n",
        "\n",
        "  for i in range(len(dataset)):\n",
        "    img_idx = img_idx + jump \n",
        "    image, binary_seg, depth_seg  = dataset[img_idx]\n",
        "    \n",
        "    image = image.squeeze(0)\n",
        "\n",
        "    plot_subplot(image, None, fig, num_images, 0, img_idx, 'gray', 1, i)\n",
        "    plot_subplot(image, binary_seg, fig, num_images, 1, img_idx, 'gray', 0.7, i)\n",
        "    plot_subplot(image, depth_seg, fig, num_images, 2, img_idx, 'jet', 0.4, i)\n",
        "\n",
        "    if i == num_images - 1 :\n",
        "      plt.show()\n",
        "      break\n",
        "\n",
        "def plot_subplot(image, seg, fig, num_images, row_idx, img_idx, cmp, alph, i):\n",
        "  ax = plt.subplot(3, num_images , i + 1 + row_idx * num_images)\n",
        "  plt.tight_layout()\n",
        "  ax.set_title('Sample #{}'.format(img_idx))\n",
        "  ax.axis('off')\n",
        "  plt.imshow(image,cmap ='gray', aspect = 'equal')\n",
        "  if row_idx != 0:\n",
        "     plt.imshow(seg,cmap = cmp, alpha = alph, aspect = 'equal')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xzw54sUhoGcs"
      },
      "source": [
        "View original dataset\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDrT7uUpoNMJ"
      },
      "source": [
        "folder_data = BaseDataPath +\"/01\"\n",
        "\n",
        "train_dataset = CustomDataset(folder_data, generateSeg_depth = False)\n",
        "\n",
        "show_dataset(train_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEpFNxPhXO8x"
      },
      "source": [
        "Define Class for Data Augmentation\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JH0mln50XWfB"
      },
      "source": [
        "# https://imgaug.readthedocs.io/en/latest/index.html\n",
        "# https://imgaug.readthedocs.io/en/latest/source/examples_segmentation_maps.html#notebook\n",
        "# https://colab.research.google.com/drive/109vu3F1LTzD1gdVV6cho9fKGx7lzbFll#scrollTo=r8PI3SKZqY8H\n",
        "\n",
        "class ImgAugTransform:\n",
        "  def __init__(self):\n",
        "    self.aug_seq = iaa.Sequential([\n",
        "                                   # Small gaussian blur with random sigma between 0 and 0.5.\n",
        "                                   iaa.Sometimes(0.7,iaa.GaussianBlur(sigma=(0, 0.5))),\n",
        "                                   # random crops, max crop is 20% of the image size         \n",
        "                                   iaa.Sometimes(0.5,iaa.Crop(percent=(0, 0.2))), \n",
        "                                   # sharpen the image     \n",
        "                                   iaa.Sometimes(0.5,iaa.Sharpen((0.0, 1.0))),          \n",
        "                                   iaa.Sometimes(0.01,\n",
        "                                                  iaa.Affine(rotate=(-2, 2), # rotate by -5 to 5 degrees (affects segmaps)\n",
        "                                                  shear = (-2,2), # shear by -2 to 2 degrees (affects segmaps)\n",
        "                                                  translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)}, # translate_percent (“move” image on the x-/y-axis)\n",
        "                                                  scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)}) # “zoom” in/out\n",
        "                                                  ),\n",
        "                                   # apply water effect (affects segmaps)\n",
        "                                   iaa.Sometimes(0.2,iaa.ElasticTransformation(alpha=(0.0,10.0), sigma=(0.0,2.0), mode = 'nearest')),  \n",
        "                                   iaa.Sometimes(0.5,iaa.PerspectiveTransform(scale=(0.01, 0.15))),\n",
        "                                   # Flip/mirror input images horizontally.\n",
        "                                   iaa.Sometimes(0.3,iaa.Fliplr()),\n",
        "                                   # Flip/mirror input images vertically. \n",
        "                                   iaa.Sometimes(0.3,iaa.Flipud()), \n",
        "                                   ], random_order=True)\n",
        "    \n",
        "    # Convert this augmenter from a stochastic to a deterministic one\n",
        "    # in order to make the same augmentation for the sequence\n",
        "    self.aug_seq = self.aug_seq.to_deterministic() \n",
        "   \n",
        "  def __call__(self, img, seg):\n",
        "    # just in case, make sure it's an np.array\n",
        "    img = np.array(img)\n",
        "    seg = np.array(seg)\n",
        "\n",
        "    # convert seg to class SegmentationMapsOnImage\n",
        "    segmap = SegmentationMapsOnImage(seg, shape = seg.shape)\n",
        "\n",
        "    # apply augmentation\n",
        "    aug_img, aug_segmap = self.aug_seq(image = img, segmentation_maps = segmap)\n",
        "\n",
        "    # convert augmented segmentation maps back to np array \n",
        "    aug_seg = aug_segmap.get_arr();\n",
        "\n",
        "    return aug_img, aug_seg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLUKaD4xvTR0"
      },
      "source": [
        "View augmentated dataset\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wjeYIggvdvS"
      },
      "source": [
        "folder_data = BaseDataPath + \"/01\"\n",
        "\n",
        "data_transform = ImgAugTransform()\n",
        "\n",
        "train_dataset = CustomDataset(folder_data ,transform = data_transform)\n",
        "\n",
        "show_dataset(train_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNwtaZUYn2JX"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pA2bEgWV5hPf"
      },
      "source": [
        "UNet model\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6u9Lw-h-5mjG"
      },
      "source": [
        "# sources:\n",
        "# Understanding  Unet:\n",
        "#  1. https://towardsdatascience.com/u-net-b229b32b4a71\n",
        "#  2. https://towardsdatascience.com/unet-line-by-line-explanation-9b191c76baf5\n",
        "# Kaggle Challenge source code for input of 512x512\n",
        "# https://github.com/petrosgk/Kaggle-Carvana-Image-Masking-Challenge/blob/master/model/u_net.py\n",
        "# https://github.com/ugent-korea/pytorch-unet-segmentation#model\n",
        "# loss - Focal and Dice Loss\n",
        "# 1.  https://www.kaggle.com/iafoss/unet34-dice-0-87\n",
        "# 2.  https://becominghuman.ai/investigating-focal-and-dice-loss-for-the-kaggle-2018-data-science-bowl-65fb9af4f36c\n",
        "\n",
        "class UNet(nn.Module):\n",
        "  def contracting_block(self, in_channels, out_channels):\n",
        "    block = torch.nn.Sequential(\n",
        "        torch.nn.Conv2d(in_channels = in_channels,\n",
        "                        out_channels = out_channels,\n",
        "                        kernel_size = 3,\n",
        "                        padding = 1),\n",
        "        torch.nn.BatchNorm2d(out_channels),\n",
        "        torch.nn.LeakyReLU(),\n",
        "        torch.nn.Conv2d(in_channels = out_channels,\n",
        "                        out_channels = out_channels,\n",
        "                        kernel_size = 3,\n",
        "                        padding = 1),\n",
        "        torch.nn.BatchNorm2d(out_channels),\n",
        "        torch.nn.LeakyReLU(),\n",
        "        )\n",
        "    return block\n",
        "  \n",
        "  def expansive_block(self, in_channels, out_channels):\n",
        "    block = torch.nn.Sequential(\n",
        "        torch.nn.Conv2d(in_channels=in_channels,\n",
        "                        out_channels = out_channels,\n",
        "                        kernel_size = 3,\n",
        "                        padding = 1),\n",
        "        torch.nn.BatchNorm2d(out_channels),\n",
        "        torch.nn.LeakyReLU(),\n",
        "        torch.nn.Conv2d( in_channels=out_channels,\n",
        "                        out_channels = out_channels,\n",
        "                        kernel_size = 3,\n",
        "                        padding = 1),\n",
        "        torch.nn.BatchNorm2d(out_channels),\n",
        "        torch.nn.LeakyReLU(),\n",
        "        torch.nn.Conv2d( in_channels=out_channels,\n",
        "                        out_channels = out_channels,\n",
        "                        kernel_size = 3,\n",
        "                        padding = 1),\n",
        "        torch.nn.BatchNorm2d(out_channels),\n",
        "        torch.nn.LeakyReLU(),\n",
        "        )\n",
        "    return block\n",
        "\n",
        "  def upsampling_block(self, in_channels, out_channels):\n",
        "    return nn.ConvTranspose2d(\n",
        "        in_channels = in_channels,\n",
        "        out_channels = out_channels,\n",
        "        kernel_size = 3,\n",
        "        stride = 2,\n",
        "        padding=1,\n",
        "        output_padding=1)  \n",
        "    \n",
        "  def final_block(self, in_channels, out_channels):\n",
        "    block = torch.nn.Sequential(\n",
        "        torch.nn.Conv2d(in_channels = in_channels,\n",
        "                        out_channels = out_channels,\n",
        "                        kernel_size = 1),\n",
        "        #torch.nn.Sigmoid(),\n",
        "        #torch.nn.Softmax(dim = 1), \n",
        "        )    \n",
        "    return  block\n",
        "       \n",
        "  def __init__(self, in_channel, out_channel,doPrint):\n",
        "    super(UNet, self).__init__()\n",
        "    \n",
        "    self.doPrint =  doPrint\n",
        "\n",
        "    #Encode\n",
        "    self.maxpool  = nn.MaxPool2d(kernel_size = 2);\n",
        "    self.encode0a = self.contracting_block (in_channels = in_channel, out_channels= 16) \n",
        "    self.encode0  = self.contracting_block (in_channels = 16, out_channels= 32) \n",
        "    self.encode1  = self.contracting_block (in_channels = 32, out_channels= 64) \n",
        "    self.encode2  = self.contracting_block (in_channels = 64, out_channels= 128) \n",
        "    self.encode3  = self.contracting_block (in_channels = 128, out_channels= 256) \n",
        "    self.encode4  = self.contracting_block (in_channels = 256, out_channels= 512)\n",
        "    \n",
        "    # Bottleneck (center)\n",
        "    self.bottleneck = self.contracting_block (in_channels = 512, out_channels= 1024)\n",
        "    \n",
        "    # Decode\n",
        "    self.upsample4 = self.upsampling_block(in_channels = 1024, out_channels= 512) #16\n",
        "    self.decode4   = self.expansive_block (in_channels = 1024, out_channels= 512) \n",
        "\n",
        "    self.upsample3 = self.upsampling_block(in_channels = 512, out_channels= 256) #32\n",
        "    self.decode3   = self.expansive_block (in_channels = 512, out_channels= 256) \n",
        "\n",
        "    self.upsample2 = self.upsampling_block(in_channels = 256, out_channels= 128) #64\n",
        "    self.decode2   = self.expansive_block (in_channels = 256, out_channels= 128) \n",
        "    \n",
        "    self.upsample1 = self.upsampling_block(in_channels = 128, out_channels= 64)  #128\n",
        "    self.decode1   = self.expansive_block (in_channels = 128, out_channels= 64)\n",
        "\n",
        "    self.upsample0 = self.upsampling_block(in_channels = 64, out_channels= 32)  #256\n",
        "    self.decode0   = self.expansive_block (in_channels = 64, out_channels= 32)\n",
        "    \n",
        "    self.upsample0a = self.upsampling_block(in_channels = 32, out_channels= 16)  #512\n",
        "    self.decode0a   = self.expansive_block (in_channels = 32, out_channels= 16)\n",
        "    \n",
        "    # Final layer\n",
        "    self.logits = self.final_block(in_channels = 16, out_channels = out_channel)\n",
        "    \n",
        "    self.softmax_layer = torch.nn.Softmax(dim = 1);\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Encode\n",
        "    if self.doPrint: print(\"x.size() = \"+ str(x.size()))\n",
        "\n",
        "    if self.doPrint: print(\"\\n\" +  '\\033[1m' +\" Encode \" + '\\033[0m')\n",
        "\n",
        "    down0a  = self.encode0a(x)\n",
        "    if self.doPrint: print(\"down0a.size() = \"+ str(down0a.size()))\n",
        "\n",
        "    down0a_pool  = self.maxpool(down0a )\n",
        "    if self.doPrint: print(\"down0a_pool.size() = \"+ str(down0a_pool.size()))\n",
        "\n",
        "    down0 = self.encode0(down0a_pool)\n",
        "    if self.doPrint: print(\"down0.size() = \"+ str(down0.size()))\n",
        "\n",
        "    down0_pool  = self.maxpool(down0)\n",
        "    if self.doPrint: print(\"down0_pool.size() = \"+ str(down0_pool.size()))\n",
        "    \n",
        "    down1 = self.encode1(down0_pool)\n",
        "    if self.doPrint: print(\"down1.size() = \"+ str(down1.size()))\n",
        "\n",
        "    down1_pool  = self.maxpool(down1)\n",
        "    if self.doPrint: print(\"down1_pool.size() = \"+ str(down1_pool.size()))\n",
        "\n",
        "    down2 = self.encode2(down1_pool)\n",
        "    if self.doPrint: print(\"down2.size() = \"+ str(down2.size()))\n",
        "\n",
        "    down2_pool  = self.maxpool(down2)\n",
        "    if self.doPrint: print(\"down2_pool.size() = \"+ str(down2_pool.size()))\n",
        "\n",
        "    down3 = self.encode3(down2_pool)\n",
        "    if self.doPrint: print(\"down3.size() = \"+ str(down3.size()))\n",
        "\n",
        "    down3_pool  = self.maxpool(down3)\n",
        "    if self.doPrint: print(\"down3_pool.size() = \"+ str(down3_pool.size()))\n",
        "    \n",
        "    down4 = self.encode4(down3_pool)\n",
        "    if self.doPrint: print(\"down4.size() = \"+ str(down4.size()))\n",
        "\n",
        "    down4_pool  = self.maxpool(down4)\n",
        "    if self.doPrint: print(\"down4_pool.size() = \"+ str(down4_pool.size()))\n",
        "\n",
        "    # center\n",
        "    if self.doPrint: print(\"\\n\" +  '\\033[1m' +\" Center \" + '\\033[0m')\n",
        "    center  = self.bottleneck(down4_pool)\n",
        "    if self.doPrint: print(\"center .size() = \"+ str(center .size()))\n",
        "    \n",
        "    # Decode\n",
        "    if self.doPrint: print(\"\\n\" +  '\\033[1m' +\" Decode \" + '\\033[0m')\n",
        "    decode_up4 = self.upsample4(center)\n",
        "    if self.doPrint: print(\"decode_up4.size() = \"+ str(decode_up4.size()))\n",
        "    decode_cat4 = torch.cat((down4, decode_up4), axis = 1) \n",
        "    if self.doPrint: print(\"decode_cat4.size() = \"+ str(decode_cat4.size()))\n",
        "    decode_block4= self.decode4(decode_cat4)\n",
        "    if self.doPrint: print(\"decode_block4.size() = \"+ str(decode_block4.size()))\n",
        "\n",
        "    decode_up3 = self.upsample3(decode_block4)\n",
        "    if self.doPrint: print(\"decode_up3.size() = \"+ str(decode_up3.size()))\n",
        "    decode_cat3 = torch.cat((down3, decode_up3), axis = 1) \n",
        "    if self.doPrint: print(\"decode_cat3.size() = \"+ str(decode_cat3.size()))\n",
        "    decode_block3= self.decode3(decode_cat3)\n",
        "    if self.doPrint: print(\"decode_block3.size() = \"+ str(decode_block3.size()))\n",
        "\n",
        "    decode_up2 = self.upsample2(decode_block3)\n",
        "    if self.doPrint: print(\"decode_up2.size() = \"+ str(decode_up2.size()))\n",
        "    decode_cat2 = torch.cat((down2, decode_up2), axis = 1) \n",
        "    if self.doPrint: print(\"decode_cat2.size() = \"+ str(decode_cat2.size()))\n",
        "    decode_block2= self.decode2(decode_cat2)\n",
        "    if self.doPrint: print(\"decode_block2.size() = \"+ str(decode_block2.size()))\n",
        "\n",
        "    decode_up1 = self.upsample1(decode_block2)\n",
        "    if self.doPrint: print(\"decode_up1.size() = \"+ str(decode_up1.size()))\n",
        "    decode_cat1 = torch.cat((down1, decode_up1), axis = 1)\n",
        "    if self.doPrint: print(\"decode_cat1.size() = \"+ str(decode_cat1.size()))\n",
        "    decode_block1= self.decode1(decode_cat1)\n",
        "    if self.doPrint: print(\"decode_block1.size() = \"+ str(decode_block1.size()))\n",
        "\n",
        "    decode_up0 = self.upsample0(decode_block1)\n",
        "    if self.doPrint: print(\"decode_up0.size() = \"+ str(decode_up0.size()))\n",
        "    decode_cat0 = torch.cat((down0, decode_up0), axis = 1) \n",
        "    if self.doPrint: print(\"decode_cat0.size() = \"+ str(decode_cat0.size()))\n",
        "    decode_block0= self.decode0(decode_cat0)\n",
        "    if self.doPrint: print(\"decode_block0.size() = \"+ str(decode_block0.size()))\n",
        "\n",
        "    decode_up0a = self.upsample0a(decode_block0)\n",
        "    if self.doPrint: print(\"decode_up0a.size() = \"+ str(decode_up0a.size()))\n",
        "    decode_cat0a = torch.cat((down0a, decode_up0a), axis = 1)\n",
        "    if self.doPrint: print(\"decode_cat0a.size() = \"+ str(decode_cat0a.size()))\n",
        "    decode_block0a= self.decode0a(decode_cat0a)\n",
        "    if self.doPrint: print(\"decode_block0a.size() = \"+ str(decode_block0a.size()))\n",
        "    \n",
        "    # Final layer\n",
        "    if self.doPrint: print(\"\\n\" +  '\\033[1m' +\" Final Layer \" + '\\033[0m')\n",
        "    logits = self.logits (decode_block0a)\n",
        "    if self.doPrint: print(\"logits.size() = \"+ str(logits.size()))\n",
        "    softmax_layer = self.softmax_layer (logits);\n",
        "    if self.doPrint: print(\"softmax_layer.size() = \"+ str(softmax_layer.size()))\n",
        "    \n",
        "    labels= torch.argmax(softmax_layer, dim=1)\n",
        "    if self.doPrint: print(\"labels.size() = \"+ str(labels.size()))\n",
        "\n",
        "    return  logits,labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fBNIVVjOGTD"
      },
      "source": [
        "Debug class UNet\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtKOwgh2OKF5"
      },
      "source": [
        "# check the encoder with batch_size =2 \n",
        "batch_size = 2\n",
        "labels = 200\n",
        "\n",
        "# input to the network\n",
        "z = torch.randn(batch_size,1, 512 ,512) # create random image\n",
        "#z= z.unsqueeze(0)\n",
        "z= z.to(device) # move to GPU\n",
        "\n",
        "# model\n",
        "unet = UNet(in_channel= 1, out_channel = labels, doPrint = True) #out_channel represents number of segments desired\n",
        "unet=unet.to(device)  # move to GPU\n",
        "\n",
        "# output of the network\n",
        "logits,labels  = unet(z)\n",
        "\n",
        "del z\n",
        "del logits , labels\n",
        "del unet\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOH9MQ3rKcWp"
      },
      "source": [
        "DWTNet Model\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxfqsDypKMIT"
      },
      "source": [
        "# Sources:\n",
        "# https://arxiv.org/pdf/1611.08303.pdf\n",
        "# https://github.com/min2209/dwt\n",
        "# About weights initialization:  \n",
        "# https://stackoverflow.com/questions/49433936/how-to-initialize-weights-in-pytorch\n",
        "# https://towardsdatascience.com/weight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79\n",
        "    \n",
        "class DWTNet(nn.Module):\n",
        "  def __init__(self, doPrint = False, doPrintMax =False, num_labels = 16):\n",
        "    super(DWTNet, self).__init__()\n",
        "    \n",
        "    self.doPrint    =  doPrint\n",
        "    self.doPrintMax =  doPrintMax\n",
        "    self.num_labels = num_labels\n",
        "\n",
        "    ########  Direction Net ######\n",
        "    \n",
        "    self.direction_layer1 = torch.nn.Sequential(torch.nn.Conv2d(in_channels = 2,\n",
        "                                                                out_channels = 16, #64\n",
        "                                                                kernel_size = 3,\n",
        "                                                                padding = 1),\n",
        "                                                torch.nn.LeakyReLU(negative_slope = 0.01),\n",
        "                                                torch.nn.BatchNorm2d (num_features = 16),\n",
        "                                                torch.nn.Conv2d(in_channels = 16, #64\n",
        "                                                                out_channels = 16, #64\n",
        "                                                                kernel_size = 3,\n",
        "                                                                padding = 1),\n",
        "                                                torch.nn.LeakyReLU(negative_slope = 0.01),\n",
        "                                                torch.nn.BatchNorm2d (num_features = 16),\n",
        "                                                nn.MaxPool2d(kernel_size = (2, 2), stride = (2,2))\n",
        "                                                )\n",
        "    \n",
        "    self.direction_layer2 = torch.nn.Sequential(torch.nn.Conv2d(in_channels = 16,#64\n",
        "                                                                out_channels = 32, #128\n",
        "                                                                kernel_size = 3,\n",
        "                                                                padding = 1),\n",
        "                                                torch.nn.LeakyReLU(negative_slope = 0.01),\n",
        "                                                torch.nn.BatchNorm2d (num_features = 32),\n",
        "                                                torch.nn.Conv2d(in_channels = 32, #128\n",
        "                                                                out_channels = 32, #128\n",
        "                                                                kernel_size = 3,\n",
        "                                                                padding = 1),\n",
        "                                                torch.nn.LeakyReLU(negative_slope = 0.01),\n",
        "                                                torch.nn.BatchNorm2d (num_features = 32),\n",
        "                                                nn.MaxPool2d(kernel_size = (2, 2), stride = (2,2))\n",
        "                                                )\n",
        "    \n",
        "    self.direction_layer3 = torch.nn.Sequential(torch.nn.Conv2d(in_channels = 32,#128\n",
        "                                                                out_channels = 64, #256\n",
        "                                                                kernel_size = 3,\n",
        "                                                                padding = 1),\n",
        "                                                torch.nn.LeakyReLU(negative_slope = 0.01),\n",
        "                                                torch.nn.BatchNorm2d (num_features = 64),\n",
        "                                                torch.nn.Conv2d(in_channels = 64,#256\n",
        "                                                                out_channels = 64,#256\n",
        "                                                                kernel_size = 3,\n",
        "                                                                padding = 1),\n",
        "                                                torch.nn.LeakyReLU(negative_slope = 0.01),\n",
        "                                                torch.nn.BatchNorm2d (num_features = 64),\n",
        "                                                torch.nn.Conv2d(in_channels = 64,#256\n",
        "                                                                out_channels = 64,#256\n",
        "                                                                kernel_size = 3,\n",
        "                                                                padding = 1),\n",
        "                                                torch.nn.LeakyReLU(negative_slope = 0.01),\n",
        "                                                torch.nn.BatchNorm2d (num_features = 64),\n",
        "                                                )\n",
        "    \n",
        "    self.direction_layer4 = torch.nn.Sequential(torch.nn.Conv2d(in_channels = 64,#256\n",
        "                                                                out_channels = 128,#512\n",
        "                                                                kernel_size = 3,\n",
        "                                                                padding = 1),\n",
        "                                                torch.nn.LeakyReLU(negative_slope = 0.01),\n",
        "                                                torch.nn.BatchNorm2d (num_features = 128),\n",
        "                                                torch.nn.Conv2d(in_channels = 128,#512\n",
        "                                                                out_channels = 128,#512\n",
        "                                                                kernel_size = 3,\n",
        "                                                                padding = 1),\n",
        "                                                torch.nn.LeakyReLU(negative_slope = 0.01),\n",
        "                                                torch.nn.BatchNorm2d (num_features = 128),\n",
        "                                                torch.nn.Conv2d(in_channels = 128,#512\n",
        "                                                                out_channels = 128,#512\n",
        "                                                                kernel_size = 3,\n",
        "                                                                padding = 1),\n",
        "                                                torch.nn.LeakyReLU(negative_slope = 0.01),\n",
        "                                                torch.nn.BatchNorm2d (num_features = 128),\n",
        "                                                )\n",
        "    \n",
        "    self.direction_layer5 = torch.nn.Sequential(torch.nn.Conv2d(in_channels = 128, #512\n",
        "                                                                out_channels = 128,#512\n",
        "                                                                kernel_size = 3,\n",
        "                                                                padding = 1),\n",
        "                                                torch.nn.LeakyReLU(negative_slope = 0.01),\n",
        "                                                torch.nn.BatchNorm2d (num_features = 128),\n",
        "                                                torch.nn.Conv2d(in_channels = 128,#512\n",
        "                                                                out_channels = 128,#512\n",
        "                                                                kernel_size = 3,\n",
        "                                                                padding = 1),\n",
        "                                                torch.nn.LeakyReLU(negative_slope = 0.01),\n",
        "                                                torch.nn.BatchNorm2d (num_features = 128),\n",
        "                                                torch.nn.Conv2d(in_channels = 128,#512\n",
        "                                                                out_channels = 128,#512\n",
        "                                                                kernel_size = 3,\n",
        "                                                                padding = 1),\n",
        "                                                torch.nn.LeakyReLU(negative_slope = 0.01),\n",
        "                                                torch.nn.BatchNorm2d (num_features = 128)\n",
        "                                                )\n",
        "    \n",
        "    self.direction_fc5 = torch.nn.Sequential(torch.nn.Conv2d(in_channels = 128,#512\n",
        "                                                             out_channels = 128,#512\n",
        "                                                             kernel_size = 5,\n",
        "                                                             padding = 2),\n",
        "                                             torch.nn.LeakyReLU(negative_slope = 0.01),\n",
        "                                             torch.nn.BatchNorm2d (num_features = 128),\n",
        "                                             torch.nn.Conv2d(in_channels = 128,#512\n",
        "                                                             out_channels = 128,#512\n",
        "                                                             kernel_size = 1),\n",
        "                                             torch.nn.LeakyReLU(negative_slope = 0.01),\n",
        "                                             torch.nn.BatchNorm2d (num_features = 128),\n",
        "                                             torch.nn.Conv2d(in_channels = 128,#512\n",
        "                                                             out_channels = 64,#256\n",
        "                                                             kernel_size = 1),\n",
        "                                             torch.nn.LeakyReLU(negative_slope = 0.01),\n",
        "                                             torch.nn.BatchNorm2d (num_features = 64)\n",
        "                                                )\n",
        "    \n",
        "    self.direction_fc4 = torch.nn.Sequential(torch.nn.Conv2d(in_channels = 128,#512\n",
        "                                                             out_channels = 128,#512\n",
        "                                                             kernel_size = 5,\n",
        "                                                             padding = 2),\n",
        "                                             torch.nn.LeakyReLU(negative_slope = 0.01),\n",
        "                                             torch.nn.BatchNorm2d (num_features = 128),\n",
        "                                             torch.nn.Conv2d(in_channels = 128,#512\n",
        "                                                             out_channels = 128,#512\n",
        "                                                             kernel_size = 1),\n",
        "                                             torch.nn.LeakyReLU(negative_slope = 0.01),\n",
        "                                             torch.nn.BatchNorm2d (num_features = 128),\n",
        "                                             torch.nn.Conv2d(in_channels = 128,#512\n",
        "                                                             out_channels = 64,#256\n",
        "                                                             kernel_size = 1),      \n",
        "                                             torch.nn.LeakyReLU(negative_slope = 0.01),\n",
        "                                             torch.nn.BatchNorm2d (num_features = 64)\n",
        "                                                )\n",
        "    \n",
        "    self.direction_fc3 = torch.nn.Sequential(torch.nn.Conv2d(in_channels = 64,#256\n",
        "                                                             out_channels = 64,#256\n",
        "                                                             kernel_size = 5,\n",
        "                                                             padding = 2),\n",
        "                                             torch.nn.LeakyReLU(negative_slope = 0.01),\n",
        "                                             torch.nn.BatchNorm2d (num_features = 64),\n",
        "                                             torch.nn.Conv2d(in_channels = 64,#256\n",
        "                                                             out_channels = 64,#256\n",
        "                                                             kernel_size = 1),\n",
        "                                             torch.nn.LeakyReLU(negative_slope = 0.01),\n",
        "                                             torch.nn.BatchNorm2d (num_features = 64),\n",
        "                                             torch.nn.Conv2d(in_channels = 64,#256\n",
        "                                                             out_channels = 64,#256\n",
        "                                                             kernel_size = 1),\n",
        "                                             torch.nn.LeakyReLU(negative_slope = 0.01),\n",
        "                                             torch.nn.BatchNorm2d (num_features = 64),\n",
        "                                                )\n",
        "    \n",
        "    self.direction_upscore5 = nn.ConvTranspose2d(in_channels = 64,#256\n",
        "                                                 out_channels = 64,#256\n",
        "                                                 kernel_size = 8,\n",
        "                                                 stride = 4,\n",
        "                                                 padding=2)\n",
        "\n",
        "    self.direction_upscore4 = nn.ConvTranspose2d(in_channels = 64,#256\n",
        "                                                 out_channels = 64,#256\n",
        "                                                 kernel_size = 4,\n",
        "                                                 stride = 2,\n",
        "                                                 padding = 1)   \n",
        "\n",
        "    self.direction_fuse3 = torch.nn.Sequential(torch.nn.Conv2d(in_channels = 64 * 3,#256\n",
        "                                                               out_channels = 128,#512\n",
        "                                                               kernel_size = 1,\n",
        "                                                               padding = 0),\n",
        "                                               torch.nn.LeakyReLU(negative_slope = 0.01),\n",
        "                                               torch.nn.BatchNorm2d (num_features = 128),\n",
        "                                               torch.nn.Conv2d(in_channels = 128,#512\n",
        "                                                               out_channels = 128,#512\n",
        "                                                               kernel_size = 1),        \n",
        "                                               torch.nn.LeakyReLU(negative_slope = 0.01),\n",
        "                                               torch.nn.BatchNorm2d (num_features = 128),\n",
        "                                               torch.nn.Conv2d(in_channels = 128,#512\n",
        "                                                               out_channels = 2,\n",
        "                                                               kernel_size = 1),\n",
        "                                                )   \n",
        "    \n",
        "    self.direction = nn.ConvTranspose2d(in_channels = 2,\n",
        "                                        out_channels = 2,\n",
        "                                        kernel_size = 8,\n",
        "                                        stride = 4,\n",
        "                                        padding =2) \n",
        "\n",
        "    self.avgPool2d =  nn.AvgPool2d(kernel_size = (2, 2), stride = (2,2))\n",
        "    \n",
        "    ########  END Direction Net ######\n",
        "    \n",
        "    ########  Watershed Transform Net ######\n",
        "\n",
        "    self.watershed_layer1 = torch.nn.Sequential(torch.nn.Conv2d(in_channels = 2,\n",
        "                                                                out_channels = 16, #64\n",
        "                                                                kernel_size = 5,\n",
        "                                                                padding = 2),\n",
        "                                                torch.nn.LeakyReLU(negative_slope = 0.01),\n",
        "                                                torch.nn.BatchNorm2d (num_features = 16),\n",
        "                                                torch.nn.Conv2d(in_channels = 16, #64\n",
        "                                                                out_channels = 32, #128\n",
        "                                                                kernel_size = 5,\n",
        "                                                                padding = 2),\n",
        "                                                torch.nn.LeakyReLU(negative_slope = 0.01),\n",
        "                                                torch.nn.BatchNorm2d (num_features = 32),\n",
        "                                                )\n",
        "    \n",
        "    self.watershed_layer2 = torch.nn.Sequential(torch.nn.Conv2d(in_channels = 32, #128\n",
        "                                                                out_channels = 32,#128\n",
        "                                                                kernel_size = 5,\n",
        "                                                                padding = 2),\n",
        "                                                torch.nn.LeakyReLU(negative_slope = 0.01),\n",
        "                                                torch.nn.BatchNorm2d (num_features = 32),\n",
        "                                                torch.nn.Conv2d(in_channels = 32,#128\n",
        "                                                                out_channels = 32,#128\n",
        "                                                                kernel_size = 5,\n",
        "                                                                padding = 2),\n",
        "                                                torch.nn.LeakyReLU(negative_slope = 0.01),\n",
        "                                                torch.nn.BatchNorm2d (num_features = 32),\n",
        "                                                torch.nn.Conv2d(in_channels = 32,#128\n",
        "                                                                out_channels = 32,#128\n",
        "                                                                kernel_size = 5,\n",
        "                                                                padding = 2),\n",
        "                                                torch.nn.LeakyReLU(negative_slope = 0.01),\n",
        "                                                torch.nn.BatchNorm2d (num_features = 32),\n",
        "                                                torch.nn.Conv2d(in_channels = 32,#128\n",
        "                                                                out_channels = 32,#128\n",
        "                                                                kernel_size = 5,\n",
        "                                                                padding = 2),\n",
        "                                                torch.nn.LeakyReLU(negative_slope = 0.01),\n",
        "                                                torch.nn.BatchNorm2d (num_features = 32),\n",
        "                                                )\n",
        "    \n",
        "    self.watershed_fc1 = torch.nn.Sequential(torch.nn.Conv2d(in_channels = 32, #128\n",
        "                                                             out_channels = 32,#128\n",
        "                                                             kernel_size = 1),\n",
        "                                             torch.nn.LeakyReLU(negative_slope = 0.01),\n",
        "                                             torch.nn.BatchNorm2d (num_features = 32),\n",
        "                                             torch.nn.Dropout(p = 0.7 ))\n",
        "\n",
        "    self.watershed_fc2 = torch.nn.Sequential(torch.nn.Conv2d(in_channels = 32,#128\n",
        "                                                             out_channels = self.num_labels,\n",
        "                                                             kernel_size = 1),\n",
        "                                             torch.nn.LeakyReLU(negative_slope = 0.01),\n",
        "                                             torch.nn.BatchNorm2d (num_features = self.num_labels),\n",
        "                                             torch.nn.Dropout(p = 0.7 ))\n",
        "    \n",
        "    self.outputData  = nn.ConvTranspose2d(in_channels = self.num_labels,\n",
        "                                          out_channels = self.num_labels,\n",
        "                                          kernel_size = 8,\n",
        "                                          stride = 4,\n",
        "                                          padding =2)\n",
        "\n",
        "    self.softmax_layer =  torch.nn.Softmax(dim = 1);\n",
        " \n",
        "  def init_weights(self,m):   \n",
        "    for name, param in m.named_parameters():\n",
        "      if type(m) == nn.Conv2d:\n",
        "        if 'bias' in name:         \n",
        "          nn.init.constant_(param, 0.5)       \n",
        "        elif 'weight' in name:         \n",
        "\n",
        "          torch.nn.init.xavier_normal_(param, gain=1.0)\n",
        "\n",
        "\n",
        "  def forward(self, x, seg):\n",
        "   # x size   (batch_size x 1 x 512 x 512)\n",
        "   # seg size (BATCH_SIZE x 512 x512)\n",
        "   \n",
        "   if self.doPrint: print(\"x.size() = \"+ str(x.size())) , print(\"seg.size() = \"+ str(seg.size()))\n",
        "   if self.doPrintMax: print(\"x (min,max) = (\"+ str(x.min().item()) + \",\" + str(x.max().item())+\")\")\n",
        "\n",
        "   x = torch.cat((x, seg.unsqueeze(1)), axis = 1)\n",
        "   if self.doPrint: print(\"concat x.size() = \"+ str(x.size())) \n",
        "   if self.doPrintMax: print(\"concat x (min,max) = (\"+ str(x.min().item()) + \",\" + str(x.max().item())+\")\")\n",
        "\n",
        "   if self.doPrint: print(\"\\n\" +  '\\033[1m' +\" Direction Net \" + '\\033[0m')\n",
        "   \n",
        "   direction_layer1 = self.direction_layer1(x)\n",
        "   if self.doPrint: print(\" direction_layer1.size() = \"+ str(direction_layer1.size())) \n",
        "   if self.doPrintMax: print(\"direction_layer1 (min,max) = (\"+ str(direction_layer1.min().item()) + \",\" + str(direction_layer1.max().item())+\")\")\n",
        "\n",
        "   direction_layer2 = self.direction_layer2(direction_layer1)\n",
        "   if self.doPrint: print(\" direction_layer2.size() = \"+ str(direction_layer2.size()))\n",
        "   if self.doPrintMax: print(\"direction_layer2 (min,max) = (\"+ str(direction_layer2.min().item()) + \",\" + str(direction_layer2.max().item())+\")\")\n",
        "\n",
        "   direction_layer3 = self.direction_layer3(direction_layer2)\n",
        "   if self.doPrint: print(\" direction_layer3.size() = \"+ str(direction_layer3.size()))\n",
        "   if self.doPrintMax: print(\"direction_layer3 (min,max) = (\"+ str(direction_layer3.min().item()) + \",\" + str(direction_layer3.max().item())+\")\")\n",
        "\n",
        "   direction_layer3_avgpool= self.avgPool2d(direction_layer3)\n",
        "   if self.doPrint: print(\" direction_layer3_avgpool.size() = \"+ str(direction_layer3_avgpool.size())) \n",
        "   if self.doPrintMax: print(\"direction_layer3_avgpool (min,max) = (\"+ str(direction_layer3_avgpool.min().item()) + \",\" + str(direction_layer3_avgpool.max().item())+\")\")\n",
        "\n",
        "   direction_layer4 = self.direction_layer4(direction_layer3_avgpool)\n",
        "   if self.doPrint: print(\" direction_layer4.size() = \"+ str(direction_layer4.size()))\n",
        "   if self.doPrintMax: print(\"direction_layer4 (min,max) = (\"+ str(direction_layer4.min().item()) + \",\" + str(direction_layer4.max().item())+\")\")\n",
        "\n",
        "   direction_layer4_avgpool= self.avgPool2d(direction_layer4)\n",
        "   if self.doPrint: print(\" direction_layer4_avgpool.size() = \"+ str(direction_layer4_avgpool.size())) \n",
        "   if self.doPrintMax: print(\"direction_layer4_avgpool (min,max) = (\"+ str(direction_layer4_avgpool.min().item()) + \",\" + str(direction_layer4_avgpool.max().item())+\")\")\n",
        "\n",
        "   direction_layer5 = self.direction_layer5(direction_layer4_avgpool)\n",
        "   if self.doPrint: print(\" direction_layer5.size() = \"+ str(direction_layer5.size()))\n",
        "   if self.doPrintMax: print(\"direction_layer5 (min,max) = (\"+ str(direction_layer5.min().item()) + \",\" + str(direction_layer5.max().item())+\")\")\n",
        "   \n",
        "   direction_fc5 = self.direction_fc5(direction_layer5)\n",
        "   if self.doPrint: print(\" direction_fc5.size() = \"+ str(direction_fc5.size()))\n",
        "   if self.doPrintMax: print(\"direction_fc5 (min,max) = (\"+ str(direction_fc5.min().item()) + \",\" + str(direction_fc5.max().item())+\")\")\n",
        "\n",
        "   direction_fc4 = self.direction_fc4(direction_layer4)\n",
        "   if self.doPrint: print(\" direction_fc4.size() = \"+ str(direction_fc4.size()))\n",
        "   if self.doPrintMax: print(\"direction_fc4 (min,max) = (\"+ str(direction_fc4.min().item()) + \",\" + str(direction_fc4.max().item())+\")\")\n",
        "\n",
        "   direction_fc3 = self.direction_fc3(direction_layer3)\n",
        "   if self.doPrint: print(\" direction_fc3.size() = \"+ str(direction_fc3.size()))\n",
        "   if self.doPrintMax: print(\"direction_fc3 (min,max) = (\"+ str(direction_fc3.min().item()) + \",\" + str(direction_fc3.max().item())+\")\")\n",
        "\n",
        "   direction_upscore5 = self.direction_upscore5(direction_fc5)\n",
        "   if self.doPrint: print(\" direction_upscore5.size() = \"+ str(direction_upscore5.size())) \n",
        "   if self.doPrintMax: print(\"direction_upscore5 (min,max) = (\"+ str(direction_upscore5.min().item()) + \",\" + str(direction_upscore5.max().item())+\")\")\n",
        "\n",
        "   direction_upscore4 = self.direction_upscore4(direction_fc4)\n",
        "   if self.doPrint: print(\" direction_upscore4.size() = \"+ str(direction_upscore4.size())) \n",
        "   if self.doPrintMax: print(\"direction_upscore4 (min,max) = (\"+ str(direction_upscore4.min().item()) + \",\" + str(direction_upscore4.max().item())+\")\")\n",
        "\n",
        "   direction_cat_fuse3 = torch.cat((direction_fc3, direction_upscore5,direction_upscore4), axis = 1) \n",
        "   if self.doPrint: print(\" direction_cat_fuse3.size() = \"+ str(direction_cat_fuse3.size())) \n",
        "   if self.doPrintMax: print(\"direction_cat_fuse3 (min,max) = (\"+ str(direction_cat_fuse3.min().item()) + \",\" + str(direction_cat_fuse3.max().item())+\")\")\n",
        "\n",
        "   direction_fuse3 = self.direction_fuse3(direction_cat_fuse3)\n",
        "   if self.doPrint: print(\" direction_fuse3.size() = \"+ str(direction_fuse3.size())) \n",
        "   if self.doPrintMax: print(\"direction_fuse3 (min,max) = (\"+ str(direction_fuse3.min().item()) + \",\" + str(direction_fuse3.max().item())+\")\")\n",
        "\n",
        "   direction = self.direction(direction_fuse3)\n",
        "   if self.doPrint: print(\" direction.size() = \"+ str(direction.size())) \n",
        "   if self.doPrintMax: print(\"direction (min,max) = (\"+ str(direction.min().item()) + \",\" + str(direction.max().item())+\")\")\n",
        "   \n",
        "   direction_normalized =F.normalize(direction, p=2, dim=1, eps=1e-20, out=None)\n",
        "   if self.doPrint: print(\" direction_normalized.size() = \"+ str(direction_normalized.size()))\n",
        "   if self.doPrintMax: print(\"direction_normalized (min,max) = (\"+ str(direction_normalized.min().item()) + \",\" + str(direction_normalized.max().item())+\")\") \n",
        "\n",
        "   if self.doPrint: print(\"\\n\" +  '\\033[1m' +\" Watershed Transform Net \" + '\\033[0m')\n",
        "\n",
        "   watershed_layer1 =self.watershed_layer1(direction_normalized)\n",
        "   if self.doPrint: print(\" watershed_layer1.size() = \"+ str(watershed_layer1.size()))\n",
        "   if self.doPrintMax: print(\"watershed_layer1 (min,max) = (\"+ str(watershed_layer1.min().item()) + \",\" + str(watershed_layer1.max().item())+\")\") \n",
        "\n",
        "   watershed_layer1_avgpool =self.avgPool2d(watershed_layer1)\n",
        "   if self.doPrint: print(\" watershed_layer1_avgpool.size() = \"+ str(watershed_layer1_avgpool.size()))\n",
        "   if self.doPrintMax: print(\"watershed_layer1_avgpool (min,max) = (\"+ str(watershed_layer1_avgpool.min().item()) + \",\" + str(watershed_layer1_avgpool.max().item())+\")\")   \n",
        "   \n",
        "   watershed_layer2 =self.watershed_layer2(watershed_layer1_avgpool)\n",
        "   if self.doPrint: print(\" watershed_layer2.size() = \"+ str(watershed_layer2.size()))\n",
        "   if self.doPrintMax: print(\"watershed_layer2 (min,max) = (\"+ str(watershed_layer2.min().item()) + \",\" + str(watershed_layer2.max().item())+\")\")   \n",
        "   \n",
        "   watershed_layer2_avgpool =self.avgPool2d(watershed_layer2)\n",
        "   if self.doPrint: print(\" watershed_layer2_avgpool.size() = \"+ str(watershed_layer2_avgpool.size()))\n",
        "   if self.doPrintMax: print(\"watershed_layer2_avgpool (min,max) = (\"+ str(watershed_layer2_avgpool.min().item()) + \",\" + str(watershed_layer2_avgpool.max().item())+\")\")   \n",
        "   \n",
        "   watershed_fc1 =self.watershed_fc1(watershed_layer2_avgpool)\n",
        "   if self.doPrint: print(\" watershed_fc1.size() = \"+ str(watershed_fc1.size()))\n",
        "   if self.doPrintMax: print(\"watershed_fc1 (min,max) = (\"+ str(watershed_fc1.min().item()) + \",\" + str(watershed_fc1.max().item())+\")\")   \n",
        "   \n",
        "   watershed_fc2 =self.watershed_fc2(watershed_fc1)\n",
        "   if self.doPrint: print(\" watershed_fc2.size() = \"+ str(watershed_fc2.size()))\n",
        "   if self.doPrintMax: print(\"watershed_fc2 (min,max) = (\"+ str(watershed_fc2.min().item()) + \",\" + str(watershed_fc2.max().item())+\")\")  \n",
        "   \n",
        "   logits =self.outputData(watershed_fc2)\n",
        "   if self.doPrint: print(\" logits.size() = \"+ str(logits.size()))\n",
        "   if self.doPrintMax: print(\"logits (min,max) = (\"+ str(logits.min().item()) + \",\" + str(logits.max().item())+\")\")      \n",
        "   \n",
        "   softmax_layer = self.softmax_layer (logits);\n",
        "   if self.doPrint: print(\" softmax_layer.size() = \"+ str(softmax_layer.size()))\n",
        "   if self.doPrintMax: print(\"softmax_layer (min,max) = (\"+ str(softmax_layer.min().item()) + \",\" + str(softmax_layer.max().item())+\")\")\n",
        "   \n",
        "   labels= torch.argmax(softmax_layer, dim=1)\n",
        "   if self.doPrint: print(\" labels.size() = \"+ str(labels.size()))\n",
        "   if self.doPrintMax: print(\"labels (min,max) = (\"+ str(labels.min().item()) + \",\" + str(labels.max().item())+\")\") \n",
        "\n",
        "   return  logits, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtblIyL3jlaq"
      },
      "source": [
        "Debug DWTNet Model\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FTQ8pPujnsZ"
      },
      "source": [
        "# check the encoder with batch_size =2 \n",
        "batch_size = 1\n",
        "\n",
        "# input to the network\n",
        "x = torch.randn  (batch_size ,1, 512 ,512) # create random image\n",
        "seg = torch.randn(batch_size , 512 ,512) # create random image\n",
        "\n",
        "x= x.to(device) # move to GPU\n",
        "seg= seg.to(device) # move to GPU\n",
        "\n",
        "# model\n",
        "dwtnet = DWTNet(doPrint = True, doPrintMax = False) # out_channel represents number of segments desired\n",
        "dwtnet = dwtnet.to(device)  # move to GPU\n",
        "\n",
        "# output of the network\n",
        "out = dwtnet(x,seg)\n",
        "\n",
        "del x, seg\n",
        "del out\n",
        "del dwtnet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Snt-S-sVe-8n"
      },
      "source": [
        "UDWTNet Model\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "li65lz1OfDBM"
      },
      "source": [
        "class UDWTNet (nn.Module) : \n",
        "  # constructor \n",
        "  def __init__(self,unet,dwtnet):\n",
        "    super(UDWTNet, self).__init__() # call to super constructor\n",
        "  \n",
        "    self.unet   = unet\n",
        "    self.dwtnet = dwtnet\n",
        "\n",
        "  def forward(self, x):\n",
        "    _, estimate_labels  =  self.unet(x)\n",
        "    logits, estimate_depth_maps =  self.dwtnet(x, estimate_labels)\n",
        "    return logits, estimate_labels, estimate_depth_maps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOHiZXxzfn37"
      },
      "source": [
        "Debug UDWTNet model\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXs1y0xBfrVz"
      },
      "source": [
        "# check the encoder with batch_size =2 \n",
        "batch_size = 1\n",
        "\n",
        "# input to the network\n",
        "x = torch.randn  (batch_size ,1, 512 ,512) # create random image\n",
        "\n",
        "x= x.to(device) # move to GPU\n",
        "\n",
        "# model\n",
        "unet = UNet(in_channel= 1, out_channel = 2 , doPrint = True) #out_channel represents number of segments desired\n",
        "unet=unet.to(device)  # move to GPU\n",
        "dwtnet = DWTNet(doPrint = True, doPrintMax = False) # out_channel represents number of segments desired\n",
        "dwtnet = dwtnet.to(device)  # move to GPU\n",
        "\n",
        "udwtnet = UDWTNet(unet,dwtnet)\n",
        "udwtnet = udwtnet.to(device)  # move to GPU\n",
        "\n",
        "# output of the network\n",
        "logits, estimate_labels,estimate_depth_maps = udwtnet(x)\n",
        "\n",
        "del x\n",
        "del logits,estimate_labels, estimate_depth_maps\n",
        "del dwtnet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjHbE5JWoAlW"
      },
      "source": [
        "# Train supporting functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Hl71BGu1eVW"
      },
      "source": [
        "Define Load Model\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOVQLoR71hxU"
      },
      "source": [
        "def LoadUnetModel(model_save_name):\n",
        "\n",
        "  model = UNet(in_channel= 1, out_channel = 2, doPrint = False) #out_channel represents number of segments desired\n",
        "     \n",
        "  loadpath=BaseSavePath +F\"/{model_save_name}\"       \n",
        "  print ('loading model in '+ loadpath) \n",
        "  model.load_state_dict(torch.load(loadpath,map_location='cpu'))\n",
        "  \n",
        "  return model\n",
        "  \n",
        "def LoadDWTModel(model_save_name):\n",
        "  \n",
        "  model = DWTNet() \n",
        "     \n",
        "  loadpath=BaseSavePath +F\"/{model_save_name}\"       \n",
        "  print ('loading model in '+ loadpath) \n",
        "  model.load_state_dict(torch.load(loadpath,map_location='cpu'))\n",
        "  \n",
        "  return model \n",
        "\n",
        "def LoadUDWTModel(model_save_name):\n",
        "  \n",
        "  unet = UNet(in_channel= 1, out_channel = 2, doPrint= False) #out_channel represents number of segments desired\n",
        "  dwtnet = DWTNet(num_labels = 16) \n",
        "\n",
        "  model = UDWTNet(unet, dwtnet) \n",
        "     \n",
        "  loadpath=BaseSavePath +F\"/{model_save_name}\"       \n",
        "  print ('loading model in '+ loadpath) \n",
        "  model.load_state_dict(torch.load(loadpath,map_location='cpu'))\n",
        "  \n",
        "  return model \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4dLhiy98znG"
      },
      "source": [
        "Define plotModelResult\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLghle2e82xw"
      },
      "source": [
        "def plotModelResultUnet(image, true_label, estimate_label, i):  \n",
        "  # to cpu\n",
        "  image = image.cpu()\n",
        "  true_label = true_label.cpu()\n",
        "  estimate_label = estimate_label.cpu()\n",
        "  \n",
        "  fig = plt.figure(figsize = (20,10))\n",
        "  \n",
        "  ax = plt.subplot(1, 3, 1)\n",
        "  plt.tight_layout()\n",
        "  ax.set_title('Sample #{}'.format(i))\n",
        "  ax.axis('off')\n",
        "  plt.imshow(image,cmap='gray',aspect='equal')\n",
        "  \n",
        "  ax = plt.subplot(1, 3, 2)\n",
        "  plt.tight_layout()\n",
        "  ax.set_title('True label Sample #{}'.format(i))\n",
        "  ax.axis('off')\n",
        "  plt.imshow(image,cmap='gray' ,aspect='equal')\n",
        "  plt.imshow(true_label,cmap='gray', alpha=0.7, aspect='equal')\n",
        "\n",
        "  ax = plt.subplot(1, 3, 3)\n",
        "  plt.tight_layout()\n",
        "  ax.set_title('Estimate label Sample #{}'.format(i))\n",
        "  ax.axis('off')\n",
        "  plt.imshow(image,cmap='gray' ,aspect='equal')\n",
        "  plt.imshow(estimate_label,cmap='gray', alpha=0.7, aspect='equal') \n",
        "   \n",
        "  plt.show()\n",
        "\n",
        "def plotModelResultDWTNet(image, true_label, true_depth,estimate_depth, i):  \n",
        "  # to cpu\n",
        "  image = image.cpu()\n",
        "  true_label = true_label.cpu()\n",
        "  true_depth= true_depth.cpu()\n",
        "  estimate_depth = estimate_depth.cpu()\n",
        "  \n",
        "  fig = plt.figure(figsize = (20,10))\n",
        "  \n",
        "  ax = plt.subplot(1, 4, 1)\n",
        "  plt.tight_layout()\n",
        "  ax.set_title('Sample #{}'.format(i))\n",
        "  ax.axis('off')\n",
        "  plt.imshow(image,cmap='gray',aspect='equal')\n",
        "  \n",
        "  ax = plt.subplot(1, 4, 2)\n",
        "  plt.tight_layout()\n",
        "  ax.set_title('True label Sample #{}'.format(i))\n",
        "  ax.axis('off')\n",
        "  plt.imshow(image,cmap='gray' ,aspect='equal')\n",
        "  plt.imshow(true_label,cmap='gray', alpha=0.7, aspect='equal')\n",
        "\n",
        "  ax = plt.subplot(1, 4, 3)\n",
        "  plt.tight_layout()\n",
        "  ax.set_title('True depth Sample #{}'.format(i))\n",
        "  ax.axis('off')\n",
        "  plt.imshow(image,cmap='gray' ,aspect='equal')\n",
        "  plt.imshow(true_depth,cmap='jet', alpha=0.6, aspect='equal')\n",
        "\n",
        "  ax = plt.subplot(1, 4, 4)\n",
        "  plt.tight_layout()\n",
        "  ax.set_title('Estimate depth Sample #{}'.format(i))\n",
        "  ax.axis('off')\n",
        "  plt.imshow(image,cmap='gray' ,aspect='equal')\n",
        "  plt.imshow(estimate_depth,cmap='jet', alpha=0.6, aspect='equal')\n",
        "   \n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def plotModelResult(image, true_label, true_depth, estimate_label,estimate_depth, i):  \n",
        "  # to cpu\n",
        "  image = image.cpu()\n",
        "  true_label = true_label.cpu()\n",
        "  true_depth= true_depth.cpu()\n",
        "  estimate_label = estimate_label.cpu()\n",
        "  estimate_depth = estimate_depth.cpu()\n",
        "  \n",
        "  fig = plt.figure(figsize = (20,10))\n",
        "  \n",
        "  ax = plt.subplot(1, 5, 1)\n",
        "  plt.tight_layout()\n",
        "  ax.set_title('Sample #{}'.format(i))\n",
        "  ax.axis('off')\n",
        "  plt.imshow(image,cmap='gray',aspect='equal')\n",
        "  \n",
        "  ax = plt.subplot(1, 5, 2)\n",
        "  plt.tight_layout()\n",
        "  ax.set_title('True label Sample #{}'.format(i))\n",
        "  ax.axis('off')\n",
        "  plt.imshow(image,cmap='gray' ,aspect='equal')\n",
        "  plt.imshow(true_label,cmap='gray', alpha=0.7, aspect='equal')\n",
        "\n",
        "  ax = plt.subplot(1, 5, 3)\n",
        "  plt.tight_layout()\n",
        "  ax.set_title('True depth Sample #{}'.format(i))\n",
        "  ax.axis('off')\n",
        "  plt.imshow(image,cmap='gray' ,aspect='equal')\n",
        "  plt.imshow(true_depth,cmap='jet', alpha=0.6, aspect='equal')\n",
        "\n",
        "  ax = plt.subplot(1, 5, 4)\n",
        "  plt.tight_layout()\n",
        "  ax.set_title('Estimate label Sample #{}'.format(i))\n",
        "  ax.axis('off')\n",
        "  plt.imshow(image,cmap='gray' ,aspect='equal')\n",
        "  plt.imshow(estimate_label,cmap='gray', alpha=0.7, aspect='equal') \n",
        "\n",
        "  ax = plt.subplot(1, 5, 5)\n",
        "  plt.tight_layout()\n",
        "  ax.set_title('Estimate depth Sample #{}'.format(i))\n",
        "  ax.axis('off')\n",
        "  plt.imshow(image,cmap='gray' ,aspect='equal')\n",
        "  plt.imshow(estimate_depth,cmap='jet', alpha=0.6, aspect='equal')\n",
        "   \n",
        "  plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POOi_Cr5xhEu"
      },
      "source": [
        "Dice Loss\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8qO-b7WxnkM"
      },
      "source": [
        "# https://www.jeremyjordan.me/semantic-segmentation/\n",
        "# https://forums.fast.ai/t/understanding-the-dice-coefficient/5838\n",
        "# https://stackoverflow.com/questions/61488732/how-calculate-the-dice-coefficient-for-multi-class-segmentation-task-using-pytho\n",
        "# https://github.com/kevinzakka/pytorch-goodies/blob/master/losses.py\n",
        "\n",
        "# good artical about losses compare Dice vs CrossEntropy vs \n",
        "# https://arxiv.org/pdf/1911.01685.pdf\n",
        "\n",
        "def calculate_dice_loss(logits,true, eps = 1e-7):\n",
        "    \"\"\"Computes the Sørensen–Dice loss.\n",
        "    Note that PyTorch optimizers minimize a loss. In this\n",
        "    case, we would like to maximize the dice loss so we\n",
        "    return the negated dice loss.\n",
        "    Args:\n",
        "        true: a tensor of shape [Batch size  x 512 x 512].\n",
        "        logits: a tensor of shape [Batch size x numLabels x 512 x 512]. Corresponds to\n",
        "            the raw output or logits of the model.\n",
        "        eps: added to the denominator for numerical stability.\n",
        "    Returns:\n",
        "        dice_loss: the Sørensen–Dice loss.\n",
        "    \"\"\"\n",
        "\n",
        "    num_classes = logits.shape[1]\n",
        "    true = true.unsqueeze(1) # now true: a tensor of shape [Batch size x 1 x 512 x 512].\n",
        "\n",
        "    true_1_hot = torch.eye(num_classes)[true.squeeze(1)]\n",
        "    true_1_hot = true_1_hot.permute(0, 3, 1, 2).float().contiguous()\n",
        "    probas = F.softmax(logits, dim = 1)\n",
        "    \n",
        "    true_1_hot = true_1_hot.type(logits.type())\n",
        "    dims = (0,) + tuple(range(2, true.ndimension()))\n",
        "    intersection = torch.sum(probas * true_1_hot, dims)\n",
        "    cardinality = torch.sum(probas + true_1_hot, dims)\n",
        "    dice_loss = (2. * intersection / (cardinality + eps)).mean()\n",
        "    return (1 - dice_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vELxmju5AFow"
      },
      "source": [
        "IOU\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8F81peyAIdy"
      },
      "source": [
        "def calculate_iou(estimate_labels, true_labels, eps = 1e-7):\n",
        "    # You can comment out this line if you are passing tensors of equal shape\n",
        "    # But if you are passing output from UNet or something it will most probably\n",
        "    # be with the BATCH x 1 x H x W shape\n",
        "    \n",
        "    estimate_labels = estimate_labels.squeeze(1)  # BATCH x 1 x H x W => BATCH x H x W\n",
        "\n",
        "    intersection = (estimate_labels & true_labels).float().sum((1, 2))  # Will be zero if Truth=0 or Prediction=0\n",
        "    union = (estimate_labels | true_labels).float().sum((1, 2))         # Will be zero if both are 0\n",
        "    \n",
        "    iou = (intersection + eps) / (union + eps)  # We smooth our devision to avoid 0/0\n",
        "    \n",
        "    thresholded = torch.clamp(20 * (iou - 0.5), 0, 10).ceil() / 10  # This is equal to comparing with thresolds\n",
        "    \n",
        "    return thresholded.mean()  #  average across the batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARjgpa0cUMY9"
      },
      "source": [
        "Average of list\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4dbUZtOUMoX"
      },
      "source": [
        "def Average(lst): \n",
        "  if len(lst) > 0: \n",
        "    return sum(lst) / len(lst) \n",
        "  else: \n",
        "    return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLDxmUaak7DK"
      },
      "source": [
        "Post Processing of Estimated Label\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vu8zDYP5k6ht"
      },
      "source": [
        "Unet_LABELS = {\"cell\":1}#, \"cell_border\":2}\n",
        "Unet_THRESHOLD = {\"cell\":0}\n",
        "\n",
        "def PostProcessingUnet (estimate_labels, doPlot = False):\n",
        "  # estimate_labels size(BATCH_SIZE x 512 x512)\n",
        "\n",
        "  if doPlot : print(\"################### Post Processing Unet #######################\")\n",
        "  output = np.zeros(estimate_labels.size(),dtype = np.int_ )\n",
        "  \n",
        "  for i in range(output.shape[0]): #batch loop \n",
        "   current_estimate_labels = estimate_labels[i,:,:].cpu().numpy()\n",
        "   #plt.set_title(' input ')\n",
        "   for semLabel in Unet_LABELS.keys(): # label loop \n",
        "     current_MaskLabel = (current_estimate_labels > Unet_THRESHOLD[semLabel])\n",
        "     if doPlot :\n",
        "        fig = plt.figure(figsize = (20,10)) \n",
        "        ax = plt.subplot(1, 4, 1)\n",
        "        plt.imshow(current_MaskLabel,cmap='gray',aspect='equal')\n",
        "        ax.set_title(' before ')\n",
        "     current_MaskLabel = skimage.morphology.remove_small_objects(current_MaskLabel, min_size = 20)\n",
        "     \n",
        "     if doPlot :\n",
        "       ax = plt.subplot(1, 4, 2)\n",
        "       plt.imshow(current_MaskLabel,cmap='gray',aspect='equal')\n",
        "       ax.set_title(' after remove_small_objects ')\n",
        "     current_MaskLabel = skimage.morphology.remove_small_holes(current_MaskLabel ,area_threshold = 2500)\n",
        "     if doPlot :\n",
        "       ax = plt.subplot(1, 4, 3)\n",
        "       plt.imshow(current_MaskLabel,cmap='gray',aspect='equal')\n",
        "       ax.set_title(' after remove_small_holes ')\n",
        "     #current_MaskLabel = skimage.morphology.binary_dilation(current_MaskLabel ,  np.ones((3,3)).astype(np.bool) )\n",
        "     if doPlot :\n",
        "       ax = plt.subplot(1, 4, 4)\n",
        "       plt.imshow(current_MaskLabel,cmap='gray',aspect='equal')\n",
        "       ax.set_title(' after binary_dilation ') \n",
        "\n",
        "     output[i,:,:] =  current_MaskLabel  \n",
        "  \n",
        "  if doPlot :\n",
        "    fig = plt.figure(figsize = (20,10)) \n",
        "    ax = plt.subplot(1, 2, 1)\n",
        "    plt.tight_layout()\n",
        "    ax.set_title(' before PostProcessing ')\n",
        "    ax.axis('off')\n",
        "    plt.imshow(estimate_labels[0,:,:].cpu(),cmap='gray',aspect='equal')\n",
        "   \n",
        "    ax = plt.subplot(1, 2, 2)\n",
        "    plt.tight_layout()\n",
        "    ax.set_title(' after PostProcessing ')\n",
        "    ax.axis('off')\n",
        "    plt.imshow(output[0,:,:],cmap='gray' ,aspect='equal')\n",
        "  \n",
        "  output = torch.from_numpy(output) \n",
        "  return output.to(device);\n",
        "\n",
        "##############################################\n",
        "CLASS_TO_SS = {\"cell\":1}#, \"border\":2}\n",
        "#LABELS = {\"cell\":1, \"boundary\":2}\n",
        "THRESHOLD = {\"cell\":2, \"border\": 0}\n",
        "SELEM = {0: (np.ones((5,5))).astype(np.bool), # kernels \n",
        "         6: (np.ones((3,3))).astype(np.bool)}\n",
        "\n",
        "def PostProcessingDWT(depthImage_input, ssMask_input, doPlot = False):\n",
        "  if doPlot : print(\"################### Post Processing DWT #######################\")\n",
        "  resultImage = np.zeros(shape=ssMask_input.shape, dtype=np.uint8) #np.float32\n",
        "  for i in range(depthImage_input.size()[0]): # batch loop \n",
        "    depthImage = depthImage_input[i,:,:].cpu().numpy()\n",
        "    ssMask = ssMask_input[i,:,:].cpu().numpy().astype(np.int32)\n",
        "\n",
        "    for semClass in CLASS_TO_SS.keys():\n",
        "      ssCode = CLASS_TO_SS[semClass]\n",
        "      ssMaskClass = (ssMask == ssCode)\n",
        "\n",
        "      ccImage = (depthImage > THRESHOLD[semClass]) * ssMaskClass\n",
        "      \n",
        "      if doPlot :\n",
        "        fig = plt.figure(figsize = (20,10)) \n",
        "        ax = plt.subplot(1, 5, 1)\n",
        "        plt.imshow(ccImage,cmap='gray',aspect='equal')\n",
        "        ax.set_title(' before ')\n",
        " \n",
        "      # to smooth the cell edges, effect created by the thresholding  \n",
        "     # ccImage =skimage.morphology.erosion(ccImage)#, selem = disk(6))\n",
        "      ccImage= skimage.filters.median(ccImage)#,selem = np.ones((6,6)).astype(np.bool), mode='nearest') \n",
        "      if doPlot :\n",
        "        fig = plt.figure(figsize = (20,10)) \n",
        "        ax = plt.subplot(1, 5, 2)\n",
        "        plt.imshow(ccImage,cmap='gray',aspect='equal')\n",
        "        ax.set_title(' after median blur ')\n",
        "\n",
        "      ccImage = skimage.morphology.remove_small_objects(ccImage, min_size=20)\n",
        "      \n",
        "      if doPlot :\n",
        "        ax = plt.subplot(1, 5, 3)\n",
        "        plt.imshow(ccImage,cmap='gray',aspect='equal')\n",
        "        ax.set_title(' after remove_small_objects ')\n",
        "\n",
        "      ccImage = skimage.morphology.remove_small_holes(ccImage,area_threshold = 2500)\n",
        "      \n",
        "      if doPlot :\n",
        "        ax = plt.subplot(1, 5, 4)\n",
        "        plt.imshow(ccImage,cmap='gray',aspect='equal')\n",
        "        ax.set_title(' after remove_small_holes ')\n",
        "        \n",
        "      #ccImage =skimage.morphology.binary_dilation(ccImage, (np.ones((5,5))).astype(np.bool))\n",
        "      if doPlot :\n",
        "        ax = plt.subplot(1, 5, 5)\n",
        "        plt.imshow(ccImage,cmap='gray',aspect='equal')\n",
        "        ax.set_title(' after binary_dilation ')\n",
        "\n",
        "      resultImage[i,:,:] = ccImage\n",
        "      \"\"\" \n",
        "      ccLabels = skimage.morphology.label(ccImage)\n",
        "      \n",
        "      if doPlot :\n",
        "        ax = plt.subplot(1, 6, 6)\n",
        "        plt.imshow(ccLabels,cmap='jet',aspect='equal')\n",
        "        ax.set_title(' after labels ')\n",
        "      \n",
        "       \n",
        "      resultImage[i,:,:] = ccLabels\n",
        "     \n",
        "      ccIDs = np.unique(ccLabels)[1:] \n",
        "      \n",
        "      for ccID in ccIDs:\n",
        "        ccIDMask = (ccLabels == ccID)\n",
        "        #ccIDMask = skimage.morphology.binary_dilation(ccIDMask, SELEM[THRESHOLD[semClass]])\n",
        "        # ccID max size is the maximum, cells in the image. say it 100 cells \n",
        "        # ssCode is the maximum label \n",
        "        instanceID = 1000 * ssCode + ccID\n",
        "        resultImage[ccIDMask] = instanceID\n",
        "      \"\"\"\n",
        "\n",
        "  #resultImage_tot = resultImage_tot.astype(np.int16)\n",
        "\n",
        "  if doPlot:\n",
        "    fig = plt.figure(figsize = (20,10)) \n",
        "    ax = plt.subplot(1, 2, 1)\n",
        "    plt.tight_layout()\n",
        "    ax.set_title(' before PostProcessing ')\n",
        "    ax.axis('off')\n",
        "    plt.imshow(depthImage_input[0,:,:].cpu(),cmap='jet',aspect='equal')\n",
        "   \n",
        "    ax = plt.subplot(1, 2, 2)\n",
        "    plt.tight_layout()\n",
        "    ax.set_title(' after PostProcessing ')\n",
        "    ax.axis('off')\n",
        "    plt.imshow(resultImage[0,:,:],cmap='gray' ,aspect='equal')\n",
        "\n",
        "  resultImage = torch.from_numpy(resultImage).to(device)\n",
        "  return resultImage\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FfvKfnAyARq"
      },
      "source": [
        "Debug Post Processing\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vT_7j1AByEu6"
      },
      "source": [
        "folder_data = BaseDataPath +\"/01\"\n",
        "test_dataset = CustomDataset(folder_data)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size= 1 , shuffle=True, num_workers=2 )\n",
        "\n",
        "# load model\n",
        "model = LoadUnetModel(Unet_save_name);\n",
        "model=model.to(device)  # move to GPU\n",
        "\n",
        "\n",
        "# load model\n",
        "#model = LoadUDWTModel(UDWTNet_save_name)\n",
        "#model=model.to(device)  # move to GPU\n",
        "\n",
        "# declare that we at evaluation mode\n",
        "model = model.eval()\n",
        "\n",
        "for i, (images, binary_true_labels ,depth_true_maps) in enumerate(test_loader):\n",
        "  \n",
        "  _,estimate_labels=model(images.to(device))\n",
        "  estimate_labels_output = PostProcessingUnet(estimate_labels, doPlot = True)\n",
        "  del estimate_labels, estimate_labels_output\n",
        "  #_,estimate_labels,estimate_map=model(images.to(device))\n",
        "  #depthImage_output = PostProcessingDWT(estimate_map, estimate_labels, doPlot = True)\n",
        "  #del estimate_labels, estimate_map\n",
        "\n",
        "  if i > 2:\n",
        "    break\n",
        "\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRnX_jDPGQ3m"
      },
      "source": [
        "Define Gradients Graph\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sL1T_boGOre"
      },
      "source": [
        "def plot_grad_flow(named_parameters):\n",
        "    '''Plots the gradients flowing through different layers in the net during training.\n",
        "    Can be used for checking for possible gradient vanishing / exploding problems.\n",
        "    \n",
        "    Usage: Plug this function in Trainer class after loss.backwards() as \n",
        "    \"plot_grad_flow(self.model.named_parameters())\" to visualize the gradient flow'''\n",
        "    ave_grads = []\n",
        "    max_grads= []\n",
        "    layers = []\n",
        "    for n, p in named_parameters:\n",
        "        if(p.requires_grad) and (\"bias\" not in n):\n",
        "            layers.append(n)\n",
        "            ave_grads.append(p.grad.abs().mean())\n",
        "            max_grads.append(p.grad.abs().max())\n",
        "    plt.bar(np.arange(len(max_grads)), max_grads, alpha=0.1, lw=1, color=\"c\")\n",
        "    plt.bar(np.arange(len(max_grads)), ave_grads, alpha=0.1, lw=1, color=\"b\")\n",
        "    plt.hlines(0, 0, len(ave_grads)+1, lw=2, color=\"k\" )\n",
        "    plt.xticks(range(0,len(ave_grads), 1), layers, rotation=\"vertical\")\n",
        "    plt.xlim(left=0, right=len(ave_grads))\n",
        "    plt.ylim(bottom = -0.001, top=0.02) # zoom in on the lower gradient regions\n",
        "    plt.xlabel(\"Layers\")\n",
        "    plt.ylabel(\"average gradient\")\n",
        "    plt.title(\"Gradient flow\")\n",
        "    plt.grid(True)\n",
        "    plt.legend([matplotlib.lines.Line2D([0], [0], color=\"c\", lw=4),\n",
        "                matplotlib.lines.Line2D([0], [0], color=\"b\", lw=4),\n",
        "                matplotlib.lines.Line2D([0], [0], color=\"k\", lw=4)], ['max-gradient', 'mean-gradient', 'zero-gradient'], loc = 'upper left')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4cR6UJPoxvu"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rFjL4ndF6MM"
      },
      "source": [
        "Train UNet\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfSXArLEF8mB"
      },
      "source": [
        "# train dataset\n",
        "PlotDuringTraining  = False\n",
        "\n",
        "# NETWORK PARAMS\n",
        "BATCH_SIZE = 2\n",
        "NUM_LABELS = 2 \n",
        "NUM_IMAGE_CHANNELS = 1 \n",
        "NUM_EPOCHS = 100\n",
        "\n",
        "# Train loader\n",
        "folder_data = BaseDataPath +\"/01\"\n",
        "# divide to train and validation\n",
        "dataset = CustomDataset(folder_data)\n",
        "dataset_len = len(dataset)\n",
        "dataset_indices = [[x] for x in range(dataset_len)]\n",
        "picked = random.sample(dataset_indices,math.floor(.7*dataset_len))\n",
        "flat_list = []\n",
        "for sublist in picked:\n",
        "    for item in sublist:\n",
        "        flat_list.append(item)\n",
        "picked = flat_list \n",
        "\n",
        "train_indices=[]\n",
        "valid_indices=[]\n",
        "for i in range (dataset_len):\n",
        "  if i in picked:\n",
        "    train_indices.append(i)\n",
        "  else:\n",
        "    valid_indices.append(i)\n",
        "\n",
        "\n",
        "unet = UNet(in_channel= NUM_IMAGE_CHANNELS, out_channel = NUM_LABELS, doPrint = False) #out_channel represents number of segments desired\n",
        "unet=unet.to(device)  # move to GPU\n",
        "\n",
        "#loss\n",
        "CrossEntropy_criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = torch.optim.SGD(unet.parameters(), lr = 0.01, momentum=0.99)\n",
        "optimizer.zero_grad()\n",
        "\n",
        "row_list = []\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  train_loss_list = []\n",
        "  train_iou_list  = []\n",
        "  \n",
        "  valid_loss_list = []\n",
        "  valid_iou_list  = []\n",
        "  \n",
        "  data_transform = ImgAugTransform()\n",
        "  train_dataset = CustomDataset(folder_data, transform =  data_transform)\n",
        "  train_loader = torch.utils.data.DataLoader(torch.utils.data.Subset(train_dataset, train_indices), batch_size= BATCH_SIZE , shuffle=True, num_workers=2 )\n",
        "  valid_loader = torch.utils.data.DataLoader(torch.utils.data.Subset(train_dataset, valid_indices), batch_size= BATCH_SIZE , shuffle=True, num_workers=2 )\n",
        "  #print('epoch = ' + str(epoch))\n",
        "  #show_dataset(train_dataset)\n",
        "\n",
        "  epoch_time_start = time.time();\n",
        "  ## training loop\n",
        "  unet = unet.train() # declare training\n",
        "  for i, (images, true_labels,_) in enumerate(train_loader):\n",
        "\n",
        "    images = images.to(device)           #move to gpu   # images size (BATCH_SIZE x 1 x 512 x512)\n",
        "    true_labels = true_labels.to(device) #move to gpu   # true_labels size(BATCH_SIZE x 512 x512)\n",
        "  \n",
        "    logits,estimate_labels = unet(images)  # logits size (BATCH_SIZE x NUM_LABELS x 512 x512) ,  estimate_labels size(BATCH_SIZE x 1 x 512 x512)\n",
        "    \n",
        "    # loss values\n",
        "    CrossEntropy_Loss = CrossEntropy_criterion(logits, true_labels)\n",
        "    dice_loss =  calculate_dice_loss(logits,true_labels)\n",
        "    \n",
        "    iou = calculate_iou(estimate_labels, true_labels)\n",
        "\n",
        "    loss = CrossEntropy_Loss # dice_loss \n",
        "\n",
        "    # Back propagation\n",
        "    unet.zero_grad()\n",
        "    loss.backward()\n",
        "    #plot_grad_flow(unet.named_parameters())\n",
        "    optimizer.step()\n",
        "\n",
        "    train_loss_list.append(loss.item())\n",
        "    train_iou_list.append(iou.item())\n",
        "      \n",
        "    del images , true_labels\n",
        "    del logits, estimate_labels\n",
        "    del loss , dice_loss, iou\n",
        "\n",
        "  ## end train_loop\n",
        "\n",
        "  ## validation loop \n",
        "  unet = unet.eval() # declare validation\n",
        "  with torch.no_grad():\n",
        "    for i, (images, true_labels,_) in enumerate(valid_loader):\n",
        "\n",
        "      images = images.to(device)           #move to gpu   # images size (BATCH_SIZE x 1 x 512 x512)\n",
        "      true_labels = true_labels.to(device) #move to gpu   # true_labels size(BATCH_SIZE x 512 x512)\n",
        "        \n",
        "      logits,estimate_labels = unet(images)  # logits size (BATCH_SIZE x NUM_LABELS x 512 x512) ,  estimate_labels size(BATCH_SIZE x 512 x512)\n",
        "\n",
        "      # loss values\n",
        "      dice_loss =  calculate_dice_loss(logits,true_labels)\n",
        "      CrossEntropy_Loss = CrossEntropy_criterion(logits, true_labels)\n",
        "      loss = CrossEntropy_Loss #dice_loss\n",
        "\n",
        "      iou = calculate_iou(estimate_labels, true_labels)\n",
        "        \n",
        "      if PlotDuringTraining: \n",
        "        if i == 0:\n",
        "          #show validation process on the validation data\n",
        "          image = images[0,:,:,:]\n",
        "          image = image.squeeze(0)\n",
        "          true_label = true_labels[0,:,:]\n",
        "          estimate_label= estimate_labels[0,:,:]\n",
        "            \n",
        "          plotModelResultUnet(image , true_label , estimate_label , epoch)\n",
        "\n",
        "          del image, true_label , estimate_label\n",
        "              \n",
        "      valid_loss_list.append(loss.item())\n",
        "      valid_iou_list.append(iou.item())\n",
        "\n",
        "\n",
        "      del images , true_labels\n",
        "      del logits, estimate_labels\n",
        "      del loss, dice_loss, iou, CrossEntropy_Loss\n",
        "\n",
        "    # end train_loop\n",
        "    \n",
        " ##end validation loop \n",
        "\n",
        "  avrg_train_loss =  Average(train_loss_list)\n",
        "  avrg_train_iou  =  Average(train_iou_list)\n",
        "  \n",
        "  avrg_valid_loss =  Average(valid_loss_list)\n",
        "  avrg_valid_iou  =  Average(valid_iou_list)\n",
        "\n",
        "  time_end =  time.time() - epoch_time_start # get end time\n",
        "  print('Epoch {}/{} | '.format(epoch + 1, NUM_EPOCHS),end =' ')\n",
        "  print('Time {:.3} sec | '.format(time_end),end =' ')\n",
        "  print('train_loss {:.3f} | '.format(avrg_train_loss),end =' ')\n",
        "  print('train_iou {:.3f} | '.format(avrg_train_iou),end =' ')\n",
        "  print('validation_loss {:.3f} | '.format(avrg_valid_loss),end =' ')\n",
        "  print('validation_iou {:.3f} | '.format(avrg_valid_iou))\n",
        "\n",
        "  #print summary in table\n",
        "  row_list.append([time_end, epoch+1, avrg_train_loss, avrg_train_iou, avrg_valid_loss, avrg_valid_iou])\n",
        "\n",
        "\n",
        "#end epoch loop\n",
        "savepath = BaseSavePath + F\"/{Unet_save_name}\"\n",
        "print ('saving model in '+ savepath)\n",
        "torch.save(unet.state_dict(), savepath)\n",
        "\n",
        "\n",
        "#Graph : Train, validation\n",
        "fig = plt.figure(figsize = (20,10))\n",
        "\n",
        "ax = plt.subplot(1, 2, 1)\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('epoch')\n",
        "train_list = [item[2] for item in row_list]\n",
        "valid_list = [item[4] for item in row_list]\n",
        "plt.plot(train_list, label = ' TRAIN loss' , color = 'r') #linestyle='dashed'\n",
        "plt.plot(valid_list, label = ' VALID loss' , color = 'b')\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='best', borderaxespad=0.)\n",
        "plt.grid(True)\n",
        "\n",
        "ax = plt.subplot(1, 2, 2)\n",
        "plt.ylabel('IOU')\n",
        "plt.xlabel('epoch')\n",
        "train_list = [item[3] for item in row_list]\n",
        "valid_list = [item[5] for item in row_list]\n",
        "plt.plot(train_list, label = ' TRAIN iou' , color = 'r') #linestyle='dashed'\n",
        "plt.plot(valid_list, label = ' VALID iou' , color = 'b')\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='best', borderaxespad=0.)\n",
        "plt.grid(True)\n",
        "plt.show\n",
        "\n",
        "del unet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Hm97LrC1LH3"
      },
      "source": [
        "Test Unet\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcvmBv8w2BzW"
      },
      "source": [
        "folder_data = BaseDataPath +\"/02\"\n",
        "test_dataset = CustomDataset(folder_data)\n",
        "\n",
        "# NETWORK PARAMS\n",
        "BATCH_SIZE = 2\n",
        "NUM_LABELS = 2 \n",
        "NUM_IMAGE_CHANNELS = 1 \n",
        "\n",
        "#loss\n",
        "CrossEntropy_criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = BATCH_SIZE , shuffle=True, num_workers=2)\n",
        "\n",
        "# load model\n",
        "model = LoadUnetModel(Unet_save_name);\n",
        "model=model.to(device)  # move to GPU\n",
        "\n",
        "# init losses_test\n",
        "losses_test =[]\n",
        "iou_test   = [];\n",
        "\n",
        "# declare that we at evaluation mode\n",
        "model = model.eval()\n",
        "\n",
        "for i, (images, true_labels,_) in enumerate(test_loader):\n",
        "\n",
        "  images = images.to(device)           #move to gpu   # images size (BATCH_SIZE x 1 x 512 x512)\n",
        "  true_labels = true_labels.to(device) #move to gpu   # true_labels size(BATCH_SIZE x 512 x512)\n",
        "  \n",
        "  logits,estimate_labels = model(images)  # logits size (BATCH_SIZE x NUM_LABELS x 512 x512) ,  estimate_labels size(BATCH_SIZE x 512 x512)\n",
        "  \n",
        "  #post processing estimate_labels\n",
        "  estimate_labels = PostProcessingUnet(estimate_labels)\n",
        "\n",
        "  # calculate the loss\n",
        "  CrossEntropy_Loss = CrossEntropy_criterion(logits, true_labels)\n",
        "  dice_loss =  calculate_dice_loss(logits,true_labels)\n",
        "  \n",
        "  iou = calculate_iou(estimate_labels, true_labels)\n",
        "  \n",
        "  #print(iou)\n",
        "\n",
        "  test_loss = CrossEntropy_Loss#dice_loss\n",
        "\n",
        "  losses_test.append(test_loss.item())\n",
        "  iou_test.append(iou)\n",
        "  # display the first  result\n",
        "  if i < 10 :\n",
        "    #print(i)\n",
        "    image = images[0,:,:,:]\n",
        "    image = image.squeeze(0)\n",
        "    true_label = true_labels[0,:,:]\n",
        "    estimate_label= estimate_labels[0,:,:]\n",
        "    \n",
        "    plotModelResultUnet(image , true_label , estimate_label , i)\n",
        "\n",
        "    del image , true_label , estimate_label\n",
        "\n",
        "  # end display first result\n",
        "\n",
        "  del images\n",
        "  del true_labels\n",
        "  del logits , estimate_labels\n",
        "  del test_loss\n",
        "\n",
        "loss_average = Average (losses_test)\n",
        "iou_average  = Average (iou_test)\n",
        "print(' Average Loss on the test data = {:.3f}  '.format(loss_average))\n",
        "print(' Average IOU measurement on the test data = {:.3f}  '.format(iou_average))\n",
        "\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaZF151jKSeg"
      },
      "source": [
        "Train DWTNet\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXF0a_29KW7z"
      },
      "source": [
        "# train dataset\n",
        "PlotDuringTraining  = True\n",
        "\n",
        "# NETWORK PARAMS\n",
        "BATCH_SIZE = 1\n",
        "NUM_EPOCHS = 100\n",
        "NUM_LABELS = 16\n",
        "\n",
        "# Train loader\n",
        "folder_data = BaseDataPath +\"/01\"\n",
        "# divide to train and validation\n",
        "dataset = CustomDataset(folder_data)\n",
        "dataset_len = len(dataset)\n",
        "dataset_indices = [[x] for x in range(dataset_len)]\n",
        "picked = random.sample(dataset_indices,math.floor(.7*dataset_len))\n",
        "flat_list = []\n",
        "for sublist in picked:\n",
        "    for item in sublist:\n",
        "        flat_list.append(item)\n",
        "picked = flat_list \n",
        "\n",
        "train_indices=[]\n",
        "valid_indices=[]\n",
        "for i in range (dataset_len):\n",
        "  if i in picked:\n",
        "    train_indices.append(i)\n",
        "  else:\n",
        "    valid_indices.append(i)\n",
        "\n",
        "dwtnet = DWTNet(doPrint = False, doPrintMax = False, num_labels = NUM_LABELS) \n",
        "dwtnet=dwtnet.to(device)  # move to GPU\n",
        "\n",
        "# Load U-net \n",
        "unet = LoadUnetModel(Unet_save_name)\n",
        "unet = unet.to(device)\n",
        "unet.eval() # declare evaluation mode for unet\n",
        "\n",
        "# use the modules apply function to recursively apply the initialization\n",
        "dwtnet.apply(dwtnet.init_weights)\n",
        "\n",
        "# Loss function\n",
        "weights = torch.ones (16,dtype = torch.float) \n",
        "#weights[1:5] = 3.0\n",
        "CrossEntropy_criterion = torch.nn.CrossEntropyLoss(weight= weights.to(device))\n",
        "\n",
        "# Optimizer\n",
        "optimizer = torch.optim.SGD(dwtnet.parameters(), lr =0.1, momentum=0.5) #0.001\n",
        "#optimizer = torch.optim.Adam(dwtnet.parameters(), lr=5e-6)\n",
        "optimizer.zero_grad()\n",
        "\n",
        "row_list = []\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  train_loss_list = []\n",
        "  train_iou_list  = []\n",
        "  train_iou_binary_list = []\n",
        "  \n",
        "  valid_loss_list = []\n",
        "  valid_iou_list  = []\n",
        "  valid_iou_binary_list =[]\n",
        "  \n",
        "\n",
        "  data_transform = ImgAugTransform()\n",
        "  train_dataset = CustomDataset(folder_data, transform =  data_transform)\n",
        "  train_loader = torch.utils.data.DataLoader(torch.utils.data.Subset(train_dataset, train_indices), batch_size= BATCH_SIZE , shuffle=True, num_workers=2 )\n",
        "  valid_loader = torch.utils.data.DataLoader(torch.utils.data.Subset(train_dataset, valid_indices), batch_size= BATCH_SIZE , shuffle=True, num_workers=2 )\n",
        "\n",
        "\n",
        "  epoch_time_start = time.time();\n",
        "  ## training loop\n",
        "  dwtnet = dwtnet.train() # declare training\n",
        "  for i, (images, binary_true_labels ,depth_true_maps) in enumerate(train_loader):\n",
        "\n",
        "    images = images.to(device)           # move to gpu   # images size (BATCH_SIZE x 1 x 512 x512)\n",
        "\n",
        "    binary_true_labels  = binary_true_labels.to(device) # move to gpu   # true_labels size(BATCH_SIZE x 512 x512)\n",
        "\n",
        "    depth_true_maps  = depth_true_maps.to(device) # move to gpu   # depth_true_map size(BATCH_SIZE x 512 x512)\n",
        "    _, unet_estimate_labels = unet(images) # unet_estimate_labels size(BATCH_SIZE x 512 x512)\n",
        "    \n",
        "    #post processing Unet\n",
        "    unet_estimate_labels = PostProcessingUnet(unet_estimate_labels,doPlot = False)\n",
        "    \n",
        "    logits, depth_estimate_maps = dwtnet(images, unet_estimate_labels)\n",
        "    #logits, depth_estimate_maps = dwtnet(images, binary_true_labels)  # logits size (BATCH_SIZE x NUM_LABELS x 512 x512) ,  depth_estimate_map size(BATCH_SIZE x 512 x512)\n",
        "    \n",
        "    # loss values\n",
        "    CrossEntropy_Loss = CrossEntropy_criterion(logits, depth_true_maps)\n",
        "    \n",
        "    iou = calculate_iou(depth_estimate_maps, depth_true_maps)\n",
        "\n",
        "    binary_estimate_maps = depth_estimate_maps.clone()\n",
        "    binary_estimate_maps[binary_estimate_maps <= 2] = 0\n",
        "    binary_estimate_maps[binary_estimate_maps > 2] = 1\n",
        "      \n",
        "    iou_binary = calculate_iou(binary_estimate_maps, binary_true_labels)\n",
        "\n",
        "    #print(iou)\n",
        "\n",
        "    loss =  CrossEntropy_Loss\n",
        "    #print(\" loss = \" + str(loss.item())) \n",
        "\n",
        "    # Back propagation\n",
        "    dwtnet.zero_grad()\n",
        "    loss.backward()\n",
        "    #plot_grad_flow(dwtnet.named_parameters())\n",
        "    optimizer.step()\n",
        "\n",
        "    train_loss_list.append(loss.item())\n",
        "    train_iou_list.append(iou.item())\n",
        "    train_iou_binary_list.append(iou_binary.item())\n",
        "    \n",
        "    del images , unet_estimate_labels , depth_true_maps # binary_true_labels\n",
        "    del logits, binary_estimate_maps,depth_estimate_maps\n",
        "    del loss , iou,iou_binary, CrossEntropy_Loss\n",
        "\n",
        "  ## end train_loop\n",
        "\n",
        "  ## validation loop\n",
        "  dwtnet = dwtnet.eval() # declare validation\n",
        "  with torch.no_grad():\n",
        "    for i, (images, binary_true_labels ,depth_true_maps) in enumerate(valid_loader):\n",
        "      \n",
        "      images = images.to(device)           # move to gpu   # images size (BATCH_SIZE x 1 x 512 x512)\n",
        "      \n",
        "      binary_true_labels  = binary_true_labels.to(device) # move to gpu   # true_labels size(BATCH_SIZE x 512 x512)\n",
        "      \n",
        "      _, unet_estimate_labels = unet(images) # unet_estimate_labels size(BATCH_SIZE x 512 x512)\n",
        "      \n",
        "      #post processing Unet\n",
        "      unet_estimate_labels = PostProcessingUnet(unet_estimate_labels,doPlot = False)\n",
        "      \n",
        "      depth_true_maps  = depth_true_maps.to(device) # move to gpu   # depth_true_map size(BATCH_SIZE x 512 x512)\n",
        "      \n",
        "      logits, depth_estimate_maps = dwtnet(images, unet_estimate_labels)  # logits size (BATCH_SIZE x NUM_LABELS x 512 x512) ,  depth_estimate_map size(BATCH_SIZE x 512 x512)\n",
        "\n",
        "      #post processing \n",
        "      #depth_estimate_maps = PostProcessing(depth_estimate_maps)\n",
        "\n",
        "      # loss values\n",
        "      CrossEntropy_Loss = CrossEntropy_criterion(logits, depth_true_maps)\n",
        "      loss =  CrossEntropy_Loss\n",
        "\n",
        "      iou = calculate_iou(depth_estimate_maps, depth_true_maps)\n",
        "      \n",
        "      binary_estimate_maps = depth_estimate_maps.clone()\n",
        "      binary_estimate_maps[binary_estimate_maps <= 2] = 0\n",
        "      binary_estimate_maps[binary_estimate_maps > 2] = 1\n",
        "      \n",
        "      iou_binary = calculate_iou(binary_estimate_maps, binary_true_labels)\n",
        "\n",
        "      if PlotDuringTraining: \n",
        "        if i == 0:\n",
        "          #show validation process on the validation data\n",
        "          image = images[0,:,:,:]\n",
        "          image = image.squeeze(0)\n",
        "          binary_true_label = binary_true_labels[0,:,:]\n",
        "          depth_estimate_map= depth_estimate_maps[0,:,:]\n",
        "          depth_true_map = depth_true_maps[0,:,:]\n",
        "          unet_estimate_labels = unet_estimate_labels[0,:,:]\n",
        "\n",
        "          plotModelResult(image, binary_true_label, depth_true_map, unet_estimate_labels,depth_estimate_map, i) \n",
        "          #plotModelResultDWTNet(image, binary_true_label, depth_true_map,depth_estimate_map, epoch)\n",
        "          \n",
        "          del image, binary_true_label , depth_estimate_map, depth_true_map\n",
        "              \n",
        "      valid_loss_list.append(loss.item())\n",
        "      valid_iou_list.append(iou.item())\n",
        "      valid_iou_binary_list.append(iou_binary.item())\n",
        "\n",
        "      del images , binary_true_labels,depth_true_maps, unet_estimate_labels\n",
        "      del logits,binary_estimate_maps, depth_estimate_maps\n",
        "      del loss, iou,iou_binary, CrossEntropy_Loss\n",
        "\n",
        "    # end train_loop\n",
        "\n",
        " ##end validation loop \n",
        "\n",
        "  avrg_train_loss =  Average(train_loss_list)\n",
        "  avrg_train_iou  =  Average(train_iou_list)\n",
        "  avrg_train_binary_iou = Average(train_iou_binary_list)\n",
        "  \n",
        "  avrg_valid_loss =  Average(valid_loss_list)\n",
        "  avrg_valid_iou  =  Average(valid_iou_list)\n",
        "  avrg_valid_binary_iou = Average(valid_iou_binary_list)\n",
        "\n",
        "  time_end =  time.time() - epoch_time_start # get end time\n",
        "  print('Epoch {}/{} | '.format(epoch + 1, NUM_EPOCHS),end =' ')\n",
        "  print('Time {:.3} sec | '.format(time_end),end =' ')\n",
        "  print('train_loss {:.3f} | '.format(avrg_train_loss),end =' ')\n",
        "  print('train_depth_iou {:.3f} | '.format(avrg_train_iou),end =' ')\n",
        "  print('train_binary_iou {:.3f} | '.format(avrg_train_binary_iou),end =' ')\n",
        "  print('validation_loss {:.3f} | '.format(avrg_valid_loss),end =' ')\n",
        "  print('validation_depth_iou {:.3f} | '.format(avrg_valid_iou),end =' ')\n",
        "  print('validation_binary_iou {:.3f} | '.format(avrg_valid_binary_iou))\n",
        "\n",
        "  #print summary in table\n",
        "  row_list.append([time_end, epoch+1, avrg_train_loss, avrg_train_iou,avrg_train_binary_iou, avrg_valid_loss, avrg_valid_iou,avrg_valid_binary_iou])\n",
        "\n",
        "\n",
        "#end epoch loop\n",
        "savepath = BaseSavePath + F\"/{DWTNet_save_name}\"\n",
        "print ('saving model in '+ savepath)\n",
        "torch.save(dwtnet.state_dict(), savepath)\n",
        "\n",
        "\n",
        "#Graph : Train, validation\n",
        "fig = plt.figure(figsize = (20,10))\n",
        "\n",
        "ax = plt.subplot(1, 3, 1)\n",
        "plt.ylabel(' Loss')\n",
        "plt.xlabel('epoch')\n",
        "train_list = [item[2] for item in row_list]\n",
        "valid_list = [item[5] for item in row_list]\n",
        "plt.plot(train_list, label = ' TRAIN loss' , color = 'r') #linestyle='dashed'\n",
        "plt.plot(valid_list, label = ' VALID loss' , color = 'b')\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='best', borderaxespad=0.)\n",
        "plt.grid(True)\n",
        "\n",
        "ax = plt.subplot(1, 3, 2)\n",
        "plt.ylabel(' IOU')\n",
        "plt.xlabel('epoch')\n",
        "train_list = [item[3] for item in row_list]\n",
        "valid_list = [item[6] for item in row_list]\n",
        "plt.plot(train_list, label = ' TRAIN depth iou' , color = 'r') #linestyle='dashed'\n",
        "plt.plot(valid_list, label = ' VALID depth iou' , color = 'b')\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='best', borderaxespad=0.)\n",
        "plt.grid(True)\n",
        "plt.show\n",
        "\n",
        "ax = plt.subplot(1, 3, 3)\n",
        "plt.ylabel('binary IOU')\n",
        "plt.xlabel('epoch')\n",
        "train_list = [item[4] for item in row_list]\n",
        "valid_list = [item[7] for item in row_list]\n",
        "plt.plot(train_list, label = ' TRAIN binary iou' , color = 'r') #linestyle='dashed'\n",
        "plt.plot(valid_list, label = ' VALID binary iou' , color = 'b')\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='best', borderaxespad=0.)\n",
        "plt.grid(True)\n",
        "plt.show\n",
        "\n",
        "\n",
        "\n",
        "del dwtnet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAtYexb3PlBC"
      },
      "source": [
        "Test DWTNet\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtTHhKu1PpWv"
      },
      "source": [
        "folder_data = BaseDataPath +\"/02\"\n",
        "test_dataset = CustomDataset(folder_data)\n",
        "\n",
        "# NETWORK PARAMS\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "# Loss function\n",
        "CrossEntropy_criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = BATCH_SIZE , shuffle=False, num_workers=2)\n",
        "\n",
        "# load model\n",
        "model = LoadDWTModel(DWTNet_save_name)\n",
        "model=model.to(device)  # move to GPU\n",
        "\n",
        "# init losses_test\n",
        "losses_test =[]\n",
        "iou_test   = []\n",
        "binary_iou_test = []\n",
        "\n",
        "# declare that we at evaluation mode\n",
        "model = model.eval()\n",
        "\n",
        "for i, (images, binary_true_labels ,depth_true_maps) in enumerate(test_loader):\n",
        "\n",
        "  images = images.to(device)           # move to gpu   # images size (BATCH_SIZE x 1 x 512 x512)\n",
        "  \n",
        "  binary_true_labels  = binary_true_labels.to(device) # move to gpu   # true_labels size(BATCH_SIZE x 512 x512)\n",
        "  \n",
        "  depth_true_maps  = depth_true_maps.to(device) # move to gpu   # depth_true_map size(BATCH_SIZE x 512 x512)\n",
        "  \n",
        "  logits, depth_estimate_maps = model(images, binary_true_labels)  # logits size (BATCH_SIZE x NUM_LABELS x 512 x512) ,  depth_estimate_map size(BATCH_SIZE x 512 x512) \n",
        "  \n",
        "  #post processing estimate_labels\n",
        "  #depth_estimate_maps = PostProcessingDWT(depth_estimate_maps, binary_true_labels, doPlot = True)\n",
        "\n",
        "  # calculate the loss\n",
        "  CrossEntropy_Loss = CrossEntropy_criterion(logits, depth_true_maps)\n",
        "  \n",
        "  iou = calculate_iou(depth_estimate_maps, depth_true_maps)\n",
        "  \n",
        "  binary_estimate_maps = depth_estimate_maps.clone()\n",
        "  binary_estimate_maps[binary_estimate_maps <= 2] = 0\n",
        "  binary_estimate_maps[binary_estimate_maps > 2] = 1\n",
        "      \n",
        "  iou_binary = calculate_iou(binary_estimate_maps, binary_true_labels)\n",
        "\n",
        "  test_loss = CrossEntropy_Loss\n",
        "\n",
        "  losses_test.append(test_loss.item())\n",
        "  iou_test.append(iou)\n",
        "  binary_iou_test.append(iou_binary)\n",
        "  # display the first  result\n",
        "  if i < 10 :\n",
        "    #print(i)\n",
        "    image = images[0,:,:,:]\n",
        "    image = image.squeeze(0)\n",
        "    binary_true_label = binary_true_labels[0,:,:]\n",
        "    depth_estimate_map= depth_estimate_maps[0,:,:]\n",
        "    depth_true_map = depth_true_maps[0,:,:]\n",
        "    \n",
        "    plotModelResultDWTNet(image, binary_true_label, depth_true_map,depth_estimate_map, i)\n",
        "          \n",
        "    del image, binary_true_label , depth_estimate_map, depth_true_map\n",
        "\n",
        "  # end display first result\n",
        "\n",
        "  del images , binary_true_labels,depth_true_maps\n",
        "  del logits, binary_estimate_maps,depth_estimate_maps\n",
        "  del test_loss, iou,iou_binary, CrossEntropy_Loss\n",
        "\n",
        "loss_average =  Average(losses_test)\n",
        "iou_average  =  Average(iou_test)\n",
        "binary_iou_average  =  Average(binary_iou_test)\n",
        "\n",
        "print(' Average Loss on the test data = {:.3f}  '.format(loss_average))\n",
        "print(' Average IOU measurement on the test data = {:.3f}  '.format(iou_average))\n",
        "print(' Average binary IOU measurement on the test data = {:.3f}  '.format(binary_iou_average))\n",
        "\n",
        "del model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06oAvKETgVbR"
      },
      "source": [
        "Train UDWTNet\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUExNJBygZFW"
      },
      "source": [
        "# train dataset\n",
        "PlotDuringTraining  = False\n",
        "\n",
        "# NETWORK PARAMS\n",
        "BATCH_SIZE = 2\n",
        "NUM_EPOCHS = 200\n",
        "\n",
        "# Train loader\n",
        "folder_data = BaseDataPath +\"/01\"\n",
        "# divide to train and validation\n",
        "dataset = CustomDataset(folder_data)\n",
        "dataset_len = len(dataset)\n",
        "dataset_indices = [[x] for x in range(dataset_len)]\n",
        "picked = random.sample(dataset_indices,math.floor(.7*dataset_len))\n",
        "flat_list = []\n",
        "for sublist in picked:\n",
        "    for item in sublist:\n",
        "        flat_list.append(item)\n",
        "picked = flat_list \n",
        "\n",
        "train_indices=[]\n",
        "valid_indices=[]\n",
        "for i in range (dataset_len):\n",
        "  if i in picked:\n",
        "    train_indices.append(i)\n",
        "  else:\n",
        "    valid_indices.append(i)\n",
        "\n",
        "  \n",
        "# models\n",
        "unet = UNet(in_channel= 1, out_channel = 2, doPrint = False) #out_channel represents number of segments desired\n",
        "\n",
        "dwtnet = DWTNet(doPrint = False, doPrintMax = False, num_labels = 16) \n",
        "dwtnet.apply(dwtnet.init_weights)\n",
        "\n",
        "udwtnet=UDWTNet(unet.to(device),dwtnet.to(device) )\n",
        "udwtnet=udwtnet.to(device)  # move to GPU\n",
        "\n",
        "# Loss function\n",
        "weights = torch.ones (16,dtype = torch.float) \n",
        "CrossEntropy_criterion = torch.nn.CrossEntropyLoss(weight= weights.to(device))\n",
        "\n",
        "# Optimizer\n",
        "optimizer = torch.optim.SGD(dwtnet.parameters(), lr =0.1, momentum=0.5) #0.001\n",
        "#optimizer = torch.optim.Adam(dwtnet.parameters(), lr=5e-6)\n",
        "optimizer.zero_grad()\n",
        "\n",
        "row_list = []\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  train_loss_list = []\n",
        "  train_iou_list  = []\n",
        "  train_iou_binary_list = []\n",
        "  \n",
        "  valid_loss_list = []\n",
        "  valid_iou_list  = []\n",
        "  valid_iou_binary_list = []\n",
        "  \n",
        "  data_transform = ImgAugTransform()\n",
        "  train_dataset = CustomDataset(folder_data, transform =  data_transform)\n",
        "  train_loader = torch.utils.data.DataLoader(torch.utils.data.Subset(train_dataset, train_indices), batch_size= BATCH_SIZE , shuffle=True, num_workers=2 )\n",
        "  valid_loader = torch.utils.data.DataLoader(torch.utils.data.Subset(train_dataset, valid_indices), batch_size= BATCH_SIZE , shuffle=True, num_workers=2 )\n",
        "\n",
        "  epoch_time_start = time.time();\n",
        "  ## training loop\n",
        "  dwtnet = dwtnet.train() # declare training\n",
        "  for i, (images, binary_true_labels ,depth_true_maps) in enumerate(train_loader):\n",
        "\n",
        "    images = images.to(device)           # move to gpu   # images size (BATCH_SIZE x 1 x 512 x512)\n",
        "\n",
        "    binary_true_labels  = binary_true_labels.to(device) # move to gpu   # depth_true_map size(BATCH_SIZE x 512 x512)\n",
        "\n",
        "    depth_true_maps  = depth_true_maps.to(device) # move to gpu   # depth_true_map size(BATCH_SIZE x 512 x512)\n",
        "\n",
        "    logits, estimate_labels,depth_estimate_maps = udwtnet(images)  # logits size (BATCH_SIZE x NUM_LABELS x 512 x512) ,  depth_estimate_map size(BATCH_SIZE x 512 x512)\n",
        "  \n",
        "    # loss values\n",
        "    CrossEntropy_Loss = CrossEntropy_criterion(logits, depth_true_maps)\n",
        "    \n",
        "    iou = calculate_iou(depth_estimate_maps, depth_true_maps)\n",
        "    #print(iou)\n",
        "    \n",
        "    binary_estimate_maps = depth_estimate_maps.clone()\n",
        "    binary_estimate_maps[binary_estimate_maps <= 2] = 0\n",
        "    binary_estimate_maps[binary_estimate_maps > 2] = 1\n",
        "      \n",
        "    iou_binary = calculate_iou(binary_estimate_maps, binary_true_labels)\n",
        "\n",
        "    loss =  CrossEntropy_Loss\n",
        "    #print(\" loss = \" + str(loss.item())) \n",
        "\n",
        "    # Back propagation\n",
        "    udwtnet.zero_grad()\n",
        "    loss.backward()\n",
        "    #plot_grad_flow(dwtnet.named_parameters())\n",
        "    optimizer.step()\n",
        "\n",
        "    train_loss_list.append(loss.item())\n",
        "    train_iou_list.append(iou.item())\n",
        "    train_iou_binary_list.append(iou_binary.item())\n",
        "    \n",
        "    del images , binary_true_labels,estimate_labels, depth_true_maps\n",
        "    del logits, binary_estimate_maps,depth_estimate_maps\n",
        "    del loss , iou,iou_binary, CrossEntropy_Loss\n",
        "\n",
        "  ## end train_loop\n",
        "\n",
        "  ## validation loop\n",
        "  dwtnet = dwtnet.eval() # declare validation\n",
        "  with torch.no_grad():\n",
        "    for i, (images, binary_true_labels ,depth_true_maps) in enumerate(valid_loader):\n",
        "      \n",
        "      images = images.to(device)           # move to gpu   # images size (BATCH_SIZE x 1 x 512 x512)\n",
        "      \n",
        "      binary_true_labels  = binary_true_labels.to(device) # move to gpu   # true_labels size(BATCH_SIZE x 512 x512)\n",
        "      \n",
        "      depth_true_maps  = depth_true_maps.to(device) # move to gpu   # depth_true_map size(BATCH_SIZE x 512 x512)\n",
        "      \n",
        "      logits,estimate_labels, depth_estimate_maps = udwtnet(images)  # logits size (BATCH_SIZE x NUM_LABELS x 512 x512) ,  depth_estimate_map size(BATCH_SIZE x 512 x512)\n",
        "\n",
        "      # loss values\n",
        "      CrossEntropy_Loss = CrossEntropy_criterion(logits, depth_true_maps)\n",
        "      loss =  CrossEntropy_Loss\n",
        "\n",
        "      iou = calculate_iou(depth_estimate_maps, depth_true_maps)\n",
        "      \n",
        "      binary_estimate_maps = depth_estimate_maps.clone()\n",
        "      binary_estimate_maps[binary_estimate_maps <= 2] = 0\n",
        "      binary_estimate_maps[binary_estimate_maps > 2] = 1\n",
        "      \n",
        "      iou_binary = calculate_iou(binary_estimate_maps, binary_true_labels)\n",
        "\n",
        "      if PlotDuringTraining: \n",
        "        if i == 0:\n",
        "          #show validation process on the validation data\n",
        "          image = images[0,:,:,:]\n",
        "          image = image.squeeze(0)\n",
        "          binary_true_label = binary_true_labels[0,:,:]\n",
        "          depth_true_map = depth_true_maps[0,:,:]\n",
        "          estimate_label =  estimate_labels[0,:,:]\n",
        "          depth_estimate_map= depth_estimate_maps[0,:,:]\n",
        "          \n",
        "          plotModelResult(image, binary_true_label, depth_true_map, estimate_label,depth_estimate_map, i) \n",
        "\n",
        "          del image, binary_true_label, depth_true_map, estimate_label,depth_estimate_map\n",
        "              \n",
        "      valid_loss_list.append(loss.item())\n",
        "      valid_iou_list.append(iou.item())\n",
        "      valid_iou_binary_list.append(iou_binary.item())\n",
        "\n",
        "      del images , binary_true_labels,depth_true_maps\n",
        "      del logits, estimate_labels,binary_estimate_maps, depth_estimate_maps\n",
        "      del loss, iou, iou_binary, CrossEntropy_Loss\n",
        "\n",
        "    # end train_loop\n",
        "\n",
        " ##end validation loop \n",
        "\n",
        "  avrg_train_loss =  Average(train_loss_list)\n",
        "  avrg_train_iou  =  Average(train_iou_list)\n",
        "  avrg_train_binary_iou  =  Average(train_iou_binary_list)\n",
        "\n",
        "  \n",
        "  avrg_valid_loss =  Average(valid_loss_list)\n",
        "  avrg_valid_iou  =  Average(valid_iou_list)\n",
        "  avrg_valid_binary_iou  =  Average(valid_iou_binary_list)\n",
        "\n",
        "  time_end =  time.time() - epoch_time_start # get end time\n",
        "  print('Epoch {}/{} | '.format(epoch + 1, NUM_EPOCHS),end =' ')\n",
        "  print('Time {:.3} sec | '.format(time_end),end =' ')\n",
        "  print('train_loss {:.3f} | '.format(avrg_train_loss),end =' ')\n",
        "  print('train_depth_iou {:.3f} | '.format(avrg_train_iou),end =' ')\n",
        "  print('train_binary_iou {:.3f} | '.format(avrg_train_binary_iou),end =' ')\n",
        "  print('validation_loss {:.3f} | '.format(avrg_valid_loss),end =' ')\n",
        "  print('validation_depth_iou {:.3f} | '.format(avrg_valid_iou),end =' ')\n",
        "  print('validation_binary_iou {:.3f} | '.format(avrg_valid_binary_iou))\n",
        "\n",
        "  #print summary in table\n",
        "  row_list.append([time_end, epoch+1, avrg_train_loss, avrg_train_iou,avrg_train_binary_iou, avrg_valid_loss, avrg_valid_iou,avrg_valid_binary_iou])\n",
        "\n",
        "#end epoch loop\n",
        "savepath = BaseSavePath + F\"/{UDWTNet_save_name}\"\n",
        "print ('saving model in '+ savepath)\n",
        "torch.save(udwtnet.state_dict(), savepath)\n",
        "\n",
        "\n",
        "#Graph : Train, validation\n",
        "fig = plt.figure(figsize = (20,10))\n",
        "\n",
        "ax = plt.subplot(1, 3, 1)\n",
        "plt.ylabel(' Loss')\n",
        "plt.xlabel('epoch')\n",
        "train_list = [item[2] for item in row_list]\n",
        "valid_list = [item[5] for item in row_list]\n",
        "plt.plot(train_list, label = ' TRAIN loss' , color = 'r') #linestyle='dashed'\n",
        "plt.plot(valid_list, label = ' VALID loss' , color = 'b')\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='best', borderaxespad=0.)\n",
        "plt.grid(True)\n",
        "\n",
        "ax = plt.subplot(1, 3, 2)\n",
        "plt.ylabel(' IOU')\n",
        "plt.xlabel('epoch')\n",
        "train_list = [item[3] for item in row_list]\n",
        "valid_list = [item[6] for item in row_list]\n",
        "plt.plot(train_list, label = ' TRAIN depth iou' , color = 'r') #linestyle='dashed'\n",
        "plt.plot(valid_list, label = ' VALID depth iou' , color = 'b')\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='best', borderaxespad=0.)\n",
        "plt.grid(True)\n",
        "plt.show\n",
        "\n",
        "ax = plt.subplot(1, 3, 3)\n",
        "plt.ylabel('binary IOU')\n",
        "plt.xlabel('epoch')\n",
        "train_list = [item[4] for item in row_list]\n",
        "valid_list = [item[7] for item in row_list]\n",
        "plt.plot(train_list, label = ' TRAIN binary iou' , color = 'r') #linestyle='dashed'\n",
        "plt.plot(valid_list, label = ' VALID binary iou' , color = 'b')\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='best', borderaxespad=0.)\n",
        "plt.grid(True)\n",
        "plt.show\n",
        "\n",
        "del dwtnet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBkeVI8EiV9G"
      },
      "source": [
        "Test UDWTNet\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8fpjse5iY6z"
      },
      "source": [
        "folder_data = BaseDataPath +\"/02\"\n",
        "test_dataset = CustomDataset(folder_data)\n",
        "\n",
        "# NETWORK PARAMS\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "# Loss function\n",
        "CrossEntropy_criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = BATCH_SIZE , shuffle=True, num_workers=2)\n",
        "\n",
        "# load model\n",
        "model = LoadUDWTModel(UDWTNet_save_name)\n",
        "model=model.to(device)  # move to GPU\n",
        "\n",
        "# init losses_test\n",
        "losses_test =[]\n",
        "iou_test   = []\n",
        "iou_binary_test = []\n",
        "\n",
        "# declare that we at evaluation mode\n",
        "model = model.eval()\n",
        "\n",
        "for i, (images, true_binary_labels ,depth_true_maps) in enumerate(test_loader):\n",
        "\n",
        "  images = images.to(device)  # move to gpu   # images size (BATCH_SIZE x 1 x 512 x512)\n",
        "  \n",
        "  true_binary_labels  = true_binary_labels.to(device) # move to gpu   # true_binary_labels size(BATCH_SIZE x 512 x512)\n",
        "\n",
        "  depth_true_maps  = depth_true_maps.to(device) # move to gpu   # depth_true_map size(BATCH_SIZE x 512 x512)\n",
        "  \n",
        "  logits,estimate_labels, depth_estimate_maps = model(images)  # logits size (BATCH_SIZE x NUM_LABELS x 512 x512) ,  depth_estimate_map size(BATCH_SIZE x 512 x512) \n",
        "  \n",
        "  #post processing estimate_labels\n",
        "  #estimate_labels = PostProcessingDWT(depth_estimate_maps, estimate_labels, doPlot = False)\n",
        "\n",
        "  # calculate the loss\n",
        "  CrossEntropy_Loss = CrossEntropy_criterion(logits, depth_true_maps)\n",
        "   \n",
        "  iou = calculate_iou(depth_estimate_maps, depth_true_maps)\n",
        "  \n",
        "  binary_estimate_maps = depth_estimate_maps.clone()\n",
        "  binary_estimate_maps[binary_estimate_maps <= 2] = 0\n",
        "  binary_estimate_maps[binary_estimate_maps > 2] = 1\n",
        "  \n",
        "  iou_binary = calculate_iou(binary_estimate_maps, true_binary_labels)\n",
        "\n",
        "  #print(iou)\n",
        "\n",
        "  test_loss = CrossEntropy_Loss\n",
        "\n",
        "  losses_test.append(test_loss.item())\n",
        "  iou_test.append(iou)\n",
        "  iou_binary_test.append(iou_binary)\n",
        "  # display the first  result\n",
        "  if i < 10 :\n",
        "    #print(i)\n",
        "    image = images[0,:,:,:]\n",
        "    image = image.squeeze(0)\n",
        "    true_binary_label = true_binary_labels[0,:,:]\n",
        "    depth_true_map= depth_true_maps[0,:,:]\n",
        "    estimate_label= estimate_labels[0,:,:]\n",
        "    depth_estimate_map= depth_estimate_maps[0,:,:]\n",
        "    \n",
        "    plotModelResult(image, true_binary_label, depth_true_map, estimate_label,depth_estimate_map, i) \n",
        "          \n",
        "    del image, true_binary_label ,depth_true_map, estimate_label,depth_estimate_map\n",
        "\n",
        "  # end display first result\n",
        "\n",
        "  del images , true_binary_labels, estimate_labels ,depth_true_maps\n",
        "  del logits, depth_estimate_maps\n",
        "  del test_loss, iou,iou_binary, CrossEntropy_Loss\n",
        "\n",
        "loss_average =  Average(losses_test)\n",
        "iou_average  =  Average(iou_test)\n",
        "iou_binary_average  =  Average(iou_binary_test)\n",
        "\n",
        "print(' Average Loss on the test data = {:.3f}  '.format(loss_average))\n",
        "print(' Average IOU measurement on the test data = {:.3f}  '.format(iou_average))\n",
        "print(' Average binary IOU measurement on the test data = {:.3f}  '.format(iou_binary_average))\n",
        "\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBCa6qWupZvW"
      },
      "source": [
        "# Test Trained Unet -> Trained DWTNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQichy6dpfti"
      },
      "source": [
        "Test Trained Unet -> Trained DWTNet\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFxNnG2Pprmo"
      },
      "source": [
        "# UNET NETWORK PARAMS\n",
        "BATCH_SIZE = 2\n",
        "NUM_LABELS = 2 \n",
        "NUM_IMAGE_CHANNELS = 1 \n",
        "\n",
        "# handle data \n",
        "folder_data = BaseDataPath +\"/02\"\n",
        "test_dataset = CustomDataset(folder_data)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = BATCH_SIZE , shuffle=True, num_workers=2)\n",
        "\n",
        "# load Unet model\n",
        "unet = LoadUnetModel(Unet_save_name);\n",
        "unet=unet.to(device)  # move to GPU\n",
        "\n",
        "# load DWT model\n",
        "dwtnet = LoadDWTModel(DWTNet_save_name)\n",
        "dwtnet=dwtnet.to(device)  # move to GPU\n",
        "\n",
        "# declare that we at evaluation mode\n",
        "unet   = unet.eval()\n",
        "dwtnet = dwtnet.eval()\n",
        "\n",
        "iou_list  = []\n",
        "binary_iou_list  = []\n",
        "\n",
        "for i, (images, binary_true_labels ,depth_true_maps) in enumerate(test_loader):\n",
        "\n",
        "  images = images.to(device)  # move to gpu   # images size (BATCH_SIZE x 1 x 512 x512)\n",
        "  \n",
        "  binary_true_labels  = binary_true_labels.to(device) # move to gpu   # true_labels size(BATCH_SIZE x 512 x512)\n",
        "  \n",
        "  depth_true_maps  = depth_true_maps.to(device) # move to gpu   # depth_true_map size(BATCH_SIZE x 512 x512)\n",
        "  \n",
        "  # Forward pass\n",
        "  unet_logits,estimate_labels = unet(images) # logits size (BATCH_SIZE x NUM_LABELS x 512 x512) ,  estimate_labels size(BATCH_SIZE x 512 x512)\n",
        "  \n",
        "  #post processing Unet\n",
        "  estimate_labels = PostProcessingUnet(estimate_labels,doPlot = False)\n",
        "  \n",
        "  dwtnet_logits, depth_estimate_maps = dwtnet(images, estimate_labels)  # logits size (BATCH_SIZE x NUM_LABELS x 512 x512) ,  depth_estimate_map size(BATCH_SIZE x 512 x512) \n",
        "\n",
        "  #post processing DWT\n",
        "  # depth_estimate_maps = PostProcessingDWT(depth_estimate_maps, estimate_labels,doPlot = True)\n",
        "  \n",
        "  # calculate the loss\n",
        "  #CrossEntropy_Loss = CrossEntropy_criterion(logits, depth_true_maps)\n",
        "  #dice_loss =  calculate_dice_loss(logits,depth_true_maps)\n",
        "  \n",
        "  iou = calculate_iou(depth_estimate_maps, depth_true_maps)\n",
        "  \n",
        "  binary_estimate_maps = depth_estimate_maps.clone()\n",
        "  binary_estimate_maps[binary_estimate_maps <= 2] = 0\n",
        "  binary_estimate_maps[binary_estimate_maps > 2] = 1\n",
        "  \n",
        "  iou_binary = calculate_iou(binary_estimate_maps, binary_true_labels)\n",
        "\n",
        "\n",
        "  iou_list.append(iou.item())\n",
        "  binary_iou_list.append(iou_binary.item())\n",
        "  # display the results\n",
        "  if i < 10 :\n",
        "    #print(i)\n",
        "    image = images[0,:,:,:]\n",
        "    image = image.squeeze(0)\n",
        "    binary_true_label = binary_true_labels[0,:,:]\n",
        "    estimate_label = estimate_labels [0,:,:]\n",
        "    depth_true_map= depth_true_maps[0,:,:]\n",
        "    depth_estimate_map= depth_estimate_maps[0,:,:]\n",
        "    \n",
        "    plotModelResult(image, binary_true_label, depth_true_map, estimate_label,depth_estimate_map, i) \n",
        "    #plotModelResultDWTNet(image, binary_true_label, depth_true_map,depth_estimate_map, i)\n",
        "\n",
        "    del image , binary_true_label ,estimate_label, depth_estimate_map, depth_true_map\n",
        "\n",
        "  # end display first result \n",
        "\n",
        "  del images, binary_true_labels , depth_true_maps # delete data\n",
        "  del unet_logits , estimate_labels  # delete unet result\n",
        "  del dwtnet_logits ,binary_estimate_maps,  depth_estimate_maps  # delete dwtnet result\n",
        "\n",
        "print(' Average IOU measurement on the test data = {:.3f}  '.format(Average(iou_list)))\n",
        "print(' Average binary IOU measurement on the test data = {:.3f}  '.format(Average(binary_iou_list)))\n",
        "\n",
        "del unet\n",
        "del dwtnet"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}